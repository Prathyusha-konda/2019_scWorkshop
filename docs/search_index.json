[
["index.html", "ANALYSIS OF SINGLE CELL RNA-SEQ DATA 1 Introduction 1.1 COURSE OVERVIEW 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND 1.3 COURSE FORMAT 1.4 Getting Started 1.5 SESSION CONTENT", " ANALYSIS OF SINGLE CELL RNA-SEQ DATA Orr Ashenberg Dana Silverbush Kirk Gosik 02/25/2019 - 03/01/2019 1 Introduction 1.1 COURSE OVERVIEW In recent years single cell RNA-seq (scRNA-seq) has become widely used for transcriptome analysis in many areas of biology. In contrast to bulk RNA-seq, scRNA-seq provides quantitative measurements of the expression of every gene in a single cell. However, to analyze scRNA-seq data, novel methods are required and some of the underlying assumptions for the methods developed for bulk RNA-seq experiments are no longer valid. In this course we will cover all steps of the scRNA-seq processing, starting from the raw reads coming off the sequencer. The course includes common analysis strategies, using state-of-the-art methods and we also discuss the central biological questions that can be addressed using scRNA-seq. 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND This course is aimed at researchers and technical workers who are or will be analyzing scRNA-seq data. The material is suitable both for experimentalists who want to learn more about data-analysis as well as computational biologists who want to learn about scRNASeq methods. Examples demonstrated in this course can be applied to any experimental protocol or biological system. The requirements for this course are: 1. Working knowledge of unix (managing files, running programs) 2. Programming experience in R (writing a function, basic I/O operations, variable types, using packages). Bioconductor experience is a plus. 3. Familiarity with next-generation sequencing data and its analyses (using alignment and quantification tools for bulk sequencing data) 1.3 COURSE FORMAT The course will be delivered over the course of five days. Each day will include a lecture and laboratory component. The lecture will introduce the topics of discussion and the laboratory sessions will be focused on practical hands-on analysis of scRNA-seq data. These sessions will involve a combination of both mirroring exercises with the instructor to demonstrate a skill as well as applying these skills on your own to complete individual exercises. After and during each exercise, interpretation of results will be discussed as a group. Computing will be done using a combination of tools installed on the attendees laptop computer and web resources accessed via web browser. 1.4 Getting Started 1.5 SESSION CONTENT 1.5.1 Monday – Classes from 09:30 to 17:30 (lunch break-1 hr, 40 min of total coffee breaks) 1.5.1.1 Lecture 1 – scRNA-Seq experimental design Overview of course General introduction: HCA/KCO overview Comparison of Bulk and single cell RNA-Seq Overview of available scRNA-seq technologies (10x) and experimental protocols scRNA-Seq experimental design and analysis workflow? 1.5.1.2 Lab 1 – Understanding sequencing raw data Lab based around data wrangling from public data repositories: get data from 10x website, single cell portal, from GEO (fastqs, counts) Shell and Unix commands to navigate directories, create folders, open files Raw file formats 1.5.1.3 Lecture 2 - Intro to Data processing: from bcl file to bam file scRNA-Seq processing workflow starting with choice of sequencer (NextSeq, HiSeq, MiSeq) / barcode swapping and bcl files Overview of Popular tools and algorithms Common single-cell analyses and interpretation Sequencing data: alignment and quality control Looking at cool things in alignment like where reads are, mutations, splicing 1.5.1.4 Lab 2 – Processing raw scRNA-Seq data Data outputs from different scRNAseq technologies (10x, Smart-seq2) - process both? Demultiplexing sequencing data Read Quality Control (CellRanger, dropEst, fastqc) Run bowtie2 on 2 wells to demonstrate alignment Read alignment and visualization (kallisto, RSEM, Igviewer) Demultiplexing FastQC Align (STAR/TOPHAT/Kallisto) IGViewer - what do we want here? I use it for mutation detections, copying sequences, searching for alternative splicing. 1.5.1.5 Flash talks (1.5 hr, break into 2 groups of 13) small presentation about your genome assembly and annotation project, ideally do 3 slides -2/3 mins (powerpoint or similar). So you can introduce yourselves and we can get to know each other. 1.5.2 Tuesday – Classes from 09:30 to 17:30 1.5.2.1 Lecture 3 – Transcriptome quantification: from bam file to counts Read &amp; UMI counting (Kallisto alignment-free pseudocounts as well), how RSEM works (length dependence, sequencing depth, multimapping reads), CellRanger (dropest), bustools 10x barcode structure and links to Perturb-seq Gene length &amp; coverage Gene expression units (count data Smart-seq2 counts or 10x UMIs vs expression data) Some R overview slides, https://r4ds.had.co.nz/ 1.5.2.2 Lab 3 - Introduction to R Installing packages Data-types Data manipulation, slicing Strings manipulations Introducing object oriented programming / S4 objects Visualization tools Bonus create FeaturePlot from Seurat in base ggplot Bonus: run RSEM on Dana’s bam files if you are bored 1.5.2.3 Lecture 4 - Expression QC, normalisation and batch correction What CellRanger does for quality filtering PBMC data Normalisation methods https://www.nature.com/articles/nmeth.4292 Doublets, empty droplets Barcode swapping Regression with technical covariates What about imputation? 1.5.2.4 Lab 4 – Data wrangling for scRNAseq data Data structures and file formats for single-cell data Quality control of cells and genes (doublets, ambient, empty drops) Data exploration: violin plots… Introducing Seurat object Genes House keeping genes Mitochondrial genes (never used these ones) Filter - Do we remove both cells and genes here? Normalize (introduce more options, other than log transform?) Find variable genes (Is it a first reduction? Why the binning?) Scaling Regression Heatmap of desired genes? Sigantures? Bonus - imputation (magic? One of the two Gocken recommended?) 1.5.2.5 Flash talks (1.5 hr, break into 2 groups of 13) small presentation about your genome assembly and annotation project, ideally do 3 slides -2/3 mins (powerpoint or similar). So you can introduce yourselves and we can get to know each other. 1.5.3 Wednesday – Classes from 09:30 to 17:30 1.5.3.1 Lecture 5 - Identifying cell populations Feature selection Dimensionality reduction Clustering and assigning identity (Louvain, NMF, topic models, variational autoencoder) Differential expression tests 1.5.3.2 Lab 5 – Feature selection &amp; Clustering analysis Parameters and clustering Comparison of feature selection methods 1.5.3.3 Lecture 6 - Introduction to batch effects Batch correction methods (regress out batch, scaling within batch, CCA, MNN, Liger, scvi, scgen) Evaluation methods for batch correction (ARI, average silhouette width, kBET…) 1.5.3.4 Lab 6 - Correcting batch effects Comparison of batch correction methods, Seurat pancreas 1.5.3.5 Poster session with beer &amp; wine (time?) Poster of current or proposed single cell genomic study. Print out would be good (recent posters are fine), or if you haven’t got a recent one, just a quick one pulled together on powerpoint and printed out on A4 is okay too - you shouldn’t stress too much about this, it’s just to connect the flash talks to the posters and it will be absolutely informal (unlike a poster session at a conference!). Take notes on how to do single-cell analysis, ideas, challenges, things you find interesting, directions you would like to explore. 1.5.4 Thursday – Classes from 09:30 to 17:30 Post poster session discussion groups 30 min discussion wrapping up poster session, and keeping track of ideas in a shared Google doc 1.5.4.1 Lecture 7 - Advanced topics: Pseudotime cell trajectories Waddington Landscape Pseudotime inference Differential expression through pseudotime 1.5.4.2 Lab 8 - Functional and Pseudotime analysis Popular tools and packages for functional analysis (https://github.com/dynverse/dynmethods#list-of-included-methods) Review concepts from papers Comparison of pseudotime methods 1.5.4.3 Lecture 8 - Single-cell multiomic technologies Introduction to other omic data types Integrating scRNA-seq with other single-cell modalities (CITE, Perturb, ATAC, methylation…) 1.5.4.4 Lab 9 - Analysis of CITE-seq, scATAC-seq https://github.com/Hoohm/CITE-seq-Count https://cite-seq.com/eccite-seq/ https://support.10xgenomics.com/single-cell-vdj/index/doc/technical-note-assay-scheme-and-configuration-of-chromium-single-cell-vdj-libraries https://satijalab.org/seurat/multimodal_vignette.html https://www.bioconductor.org/packages/devel/bioc/vignettes/cicero/inst/doc/website.html 1.5.5 Friday – Classes from 09:30 to 17:30 1.5.5.1 Lab 10 - small dataset for analysis Karthik has a good starting point: Krumlov_lab2_guidelines.html and Hemberg lab http://hemberg-lab.github.io/scRNA.seq.course/advanced-exercises.html Present a set of methods and orders in which to try them - IDH mutated glioma - Goal for first half: get to clustering and identify malignant cells (inferCNV possible) - Goal for second half: cell states - For our other courses, the last day we usually divide them in groups of 3-4 ppl and assign them a small dataset in order to repeat all the analyses they have learnt during the week, to think about the best strategy to carry out the analyses and to present the results in front of the other ppl. I believe this is something very productive and helpful because it is a kind of wrap-up and brainstorming session. Normally, ppl love to talk and present something and in this way they/we can be 100% sure they really understood the different steps of the pipeline. 1.5.5.2 Lecture 9 - Group presentations Review, Questions and Answers "],
["scrna-seq-experimental-design.html", "2 scRNA-Seq Experimental Design", " 2 scRNA-Seq Experimental Design "],
["understanding-sequencing-raw-data.html", "3 Understanding Sequencing Raw Data 3.1 Class Environment 3.2 Shell and Unix commands 3.3 File formats 3.4 Public data repositories", " 3 Understanding Sequencing Raw Data 3.1 Class Environment 3.1.1 Getting into AWS Instance ## Example ssh -i berlin.pem ubuntu@&lt;PUBLIC IP ADDRESS&gt; (e.g.34.219.254.245) ## Actual Command ssh -i berlin.pem ubuntu@34.213.180.241 3.2 Shell and Unix commands 3.2.1 Common Linux Commands 3.2.1.1 Lab 1a check the your present directory pwd check history history pipe history to grep to search for the cd command history | grep cd put history into a history.txt file history &gt; history.txt make a directory called data mkdir data change into data directory cd data move history.txt file into data directory mv ../history.txt ./ check manual page of wget command man wget redirect wget maunual page output into a file called wget.txt man wget &gt; wget.txt return the lines that contain output in the wget.txt file cat wget.txt | grep output grep -i output wget.txt Compress wget.txt file gzip wget.txt View Compressed file cat wget.txt.qz zcat wget.txt.qz zcat wget.txt.qz | less 3.2.1.2 Docker Commands Consistent compute enviornment to ensure all software that you need is on the machine and able to be used. change directory to your user directory run following command to start docker ## maybe take away the --rm so you can save the container for later ## run from your home directory cd docker run --rm -it -v $PWD/Share:/Share -v $PWD:/mydir kdgosik/scellbern2019 bash Explaination of commands - docker: command to run docker - run: asking docker to run a container - --rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - this will keep all session output displaying on the terminal - to stop container go to terminal and press Crtl+c -v $PWD/Share:/Share: map the share directory from AWS to Share inside docker container -v $PWD:/mydir: map your home directory to a directory inside docker container called home - kdgosik/scellbern2019: the image to run. It will be the image into a container if not already built on your computer - [image link](https://hub.docker.com/r/kdgosik/scellbern2019) 3.3 File formats bcl fastq bam mtx, tsv hdf5 (.h5, .h5ad) 3.3.1 View FASTQ Files 3.3.1.1 Viewing entire file cat /Share/data/Teichmann_2i_2_2_2.fastq 3.3.1.2 Viewing first 10 lines head /Share/data/Teichmann_2i_2_2_2.fastq 3.3.1.3 Stream Viewing with less command less /Share/data/Teichmann_2i_2_2_2.fastq 3.3.2 View BAM Files 3.3.2.1 Viewing first 10 lines samtools view /Share/data/pbmc_1k_protein_v3_possorted_genome_bam.bam | head 3.3.2.2 Stream Viewing with less command samtools view /Share/data/pbmc_1k_protein_v3_possorted_genome_bam.bam | less 3.4 Public data repositories 3.4.1 Cellranger/10x 3.4.1.1 Lab 1b 10x PBMC data are hosted in https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz change directory into the data directory get 10x PBMC data unzip data explore directory explore files mkdir data wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz cd .. 3.4.2 GEO https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81905 3.4.2.1 Lab 1c Get GEO Data - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL19057_series_matrix.txt.gz - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL17021_series_matrix.txt.gz make a directory for the files or use data directory go into that directory get files and place them in the directory View files (try keeping in compressed format and view that way) bash cd data wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL19057_series_matrix.txt.gz cd data; tar -xzf GSE81905-GPL19057_series_matrix.txt.gz cd .. 3.4.3 Single Cell Portal https://portals.broadinstitute.org/single_cell Study: Salk Institute - Single-cell Methylome Sequencing Identifies Distinct Neuronal Populations in Mouse Frontal Cortex 3.4.3.1 Lab 1d Get R2 fastq file from the Salk Institute study Look at files 3.4.3.2 Lab 1e Get Docker on your local computer for you to have Explore Single Cell Portal Explore GEO "],
["data-preprocessing.html", "4 Data Preprocessing", " 4 Data Preprocessing "],
["processing-scrnaseq-data.html", "5 Processing scRNAseq Data 5.1 Goal 5.2 Further reading 5.3 FastQC 5.4 Align the reads 5.5 Visualization", " 5 Processing scRNAseq Data 5.1 Goal To give you experience with examining and aligning fastq files 5.2 Further reading This lab is based on a lab given in: http://hemberg-lab.github.io/scRNA.seq.course/processing-raw-scrna-seq-data.html For more exercises and ideas please visit their web-site! 5.3 FastQC Once you’ve obtained your single-cell RNA-seq data, the first thing you need to do with it is check the quality of the reads you have sequenced. For this task, today we will be using a tool called FastQC. FastQC is a quality control tool for sequencing data, which can be used for both bulk and single-cell RNA-seq data. FastQC takes sequencing data as input and returns a report on read quality. Copy and paste this link into your browser to visit the FastQC website: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ This website contains links to download and install FastQC and documentation on the reports produced. Fortunately we have already installed FastQC for you today, so instead we will take a look at the documentation. Scroll down the webpage to ‘Example Reports’ and click ‘Good Illumina Data’. This gives an example of what an ideal report should look like for high quality Illumina reads data. Now let’s make a FastQC report ourselves. Today we will be performing our analysis using a single cell from an mESC dataset produced by (Kolodziejczyk et al. 2015). The cells were sequenced using the SMART-seq2 library preparation protocol and the reads are paired end. The files are located in Share. Now let’s look at the files: less Share/data/Teichmann_2i_2_2_1.fastq less Share/data/Teichmann_2i_2_2_2.fastq We run fastqc from /usr/local/src/FastQC. You may need to give yourself permissions to run the file (hint: chmod) Task 1: Try to work out what command you should use to produce the FastQC report. Hint: Try executing ./usr/local/src/FastQC/fastqc -h This command will tell you what options are available to pass to FastQC. Let us direct our output to our personal directories (under the folder results). Feel free to ask for help if you get stuck! If you are successful, you should generate a .zip and a .html file for both the forwards and the reverse reads files. Once you have been successful, feel free to have a go at the next section. Once the command has finished executing, you should have a total of four files - one zip file for each of the paired end reads, and one html file for each of the paired end reads. The report is in the html file. To view it, we will need to get it off AWS and onto your computer using either filezilla or scp. Ask an instructor if you are having difficulties. scp command is: scp -r -i &lt;your pem file&gt; &lt;username&gt;@ec2-34-213-180-241.us-west-2.compute.amazonaws.com:~/&lt;file to copy&gt; &lt;destination in your computer&gt; We shared a dropbox folder with you with an example outout files. If scp become complicated you can download the results from there. Once the file is on you computer, click on it. Your FastQC report should open. Have a look through the file. Remember to look at both the forwards and the reverse end read reports! How good quality are the reads? Is there anything we should be concerned about? Feel free to chat to one of the instructors about your ideas. 5.3.1 Fastq file format FastQ is the most raw form of scRNASeq data you will encounter. All scRNASeq protocols are sequenced with paired-end sequencing. Barcode sequences may occur in one or both reads depending on the protocol employed. However, protocols using unique molecular identifiers (UMIs) will generally contain one read with the cell and UMI barcodes plus adapters but without any transcript sequence. Thus reads will be mapped as if they are single-end sequenced despite actually being paired end. FastQ files have the format: &gt;ReadID READ SEQUENCE + SEQUENCING QUALITY SCORES 5.4 Align the reads 5.4.1 STAR align Now we have established that our reads are of good quality, we would like to map them to a reference genome. This process is known as alignment. Some form of alignment is generally required if we want to quantify gene expression or find genes which are differentially expressed between samples. Many tools have been developed for read alignment, but today we will focus on STAR. For each read in our reads data, STAR tries to find the longest possible sequence which matches one or more sequences in the reference genome. Because STAR is able to recognize splicing events in this way, it is described as a ‘splice aware’ aligner. Usually STAR aligns reads to a reference genome, potentially allowing it to detect novel splicing events or chromosomal rearrangements. However, one issue with STAR is that it needs a lot of RAM, especially if your reference genome is large (eg. mouse and human). To speed up our analysis today, we will use STAR to align reads from to a reference transcriptome of 2000 transcripts. Note that this is NOT normal or recommended practice, we only do it here for reasons of time. We recommend that normally you should align to a reference genome. Two steps are required to perform STAR alignment. In the first step, the user provides STAR with reference genome sequences (FASTA) and annotations (GTF), which STAR uses to create a genome index. In the second step, STAR maps the user’s reads data to the genome index. Let’s create the index now. Remember, for reasons of time we are aligning to a transcriptome rather than a genome today, meaning we only need to provide STAR with the sequences of the transcripts we will be aligning reads to. You can obtain transcriptomes for many model organisms from Ensembl (https://www.ensembl.org/info/data/ftp/index.html). Task 2: Create a genome index First create the output folder for the index in your personal folder under results (recommended STAR/indices). We run STAR from: /usr/local/src/STAR/bin/Linux_x86_64 using the command: ./usr/local/src/STAR/bin/Linux_x86_64/STAR --runThreadN 4 --runMode genomeGenerate --genomeDir &lt;output STAR indices folder&gt; --genomeFastaFiles Share/data/2000_reference.transcripts.fa Task 3: What does each of the options we used do? Hint: Use the STAR manual to help you (https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf) Now that we have created the index, we can perform the mapping step. Task 4: Try to work out what command you should use to map our fastq files to the index you created. Use the STAR manual to help you. Once you think you know the answer use ./STAR command to align the fastq files to a BAM file. You can either create a SAM file and convert it to BAM using samtools, or use STAR to directly output a BAM file (–outSAMtype BAM Unsorted) The alignment may take awhile, if you wish to you can complete tasks 7-10 in the meanwhile. Task 5: Try to understand the output of your alignment. Talk to one of the instructors if you need help! 5.4.2 Bam file format BAM file format stores mapped reads in a standard and efficient manner. The human-readable version is called a SAM file, while the BAM file is the highly compressed version. BAM/SAM files contain a header which typically includes information on the sample preparation, sequencing and mapping; and a tab-separated row for each individual alignment of each read. Alignment rows employ a standard format with the following columns: QNAME : read name (generally will include UMI barcode if applicable) FLAG : number tag indicating the “type” of alignment, link to explanation of all possible “types” RNAME : reference sequence name (i.e. chromosome read is mapped to). POS : leftmost mapping position MAPQ : Mapping quality CIGAR : string indicating the matching/mismatching parts of the read (may include soft-clipping). RNEXT : reference name of the mate/next read PNEXT : POS for mate/next read TLEN : Template length (length of reference region the read is mapped to) SEQ : read sequence QUAL : read quality BAM/SAM files can be converted to the other format using ‘samtools’: samtools view -S -b file.sam &gt; file.bam samtools view -h file.bam &gt; file.sam Some sequencing facilities will automatically map your reads to the a standard genome and deliver either BAM or CRAM formatted files. Generally they will not have included ERCC sequences in the genome thus no ERCC reads will be mapped in the BAM/CRAM file. To quantify ERCCs (or any other genetic alterations) or if you just want to use a different alignment algorithm than whatever is in the generic pipeline (often outdated), then you will need to convert the BAM/CRAM files back to FastQs: BAM files can be converted to FastQ using bedtools. To ensure a single copy for multi-mapping reads first sort by read name and remove secondary alignments using samtools. Picard also contains a method for converting BAM to FastQ files. To make our aligned BAM file easy to navigate (needed for IGViewer) we will sort and index it using samtools. Sam tools can be run from everywhere (no need to go to a special directory!) using the command: samtools Let us start by sorting the BAM file: samtools sort Aligned.out.bam -o Aligned.out.sorted.bam Task 6: can you index the file? hint: try looking at samtools -h Once you sorted and indexed the files you should have a BAM and a bai files. The BAM file is the aligned reads, and the bai is an index file. To view them in IGViewer (IGV) first copy them into your computer. Go ahead and copy the fa file as well, we will need a reference genome file. 5.5 Visualization To view the file we will use the IGV you installed on your personal computer. Open IGV: the default genomes are human HG19 and HG38. Through the class we will be using the PBMC dataset. You have the BAM file in your data folder. Go ahead and transfer it to your computer and upload it to IGV with hg38 as reference genome. Task 7: Browse to MS4A1, this is a blood cell marker. Can you see the exons and the introns? Where are most of the aligned reads? Task 8: Search in IGV or online - can you present splice junctions? (right click -&gt; “Show splice junction track”) Task 9: Try further tasks that interest you in IGV. For example, can you detect reads that are within one exon and reads that start in one exon and continue in the next? Can you copy the sequence of exon2 in MS4A1? Task 10: What would have happened if you chose the wrong reference genome, such as hg19? Bonus (IGV sometimes has difficulties loading small fa files. So if this becomes difficult - don’t worry! It’s not your alignment): The default genomes are human HG19 and HG38. However you can also upload your reference genome of choice. As we created our own fasta file we can now upload it as a reference genome. Task 11: Load new genome: go to “Genomes”-&gt;”Load from file” and load the file 2000_reference.transcripts.fa Task 12: Now load your reads: go to “File”-&gt;”Load from file” and load your BAM file. Notice that IGV needs a BAM and a bai saved in the same location. IGV uses the bai to navigate through the BAM file. Task 13: Some of the reads have a nucleotide substitution in position 993 - what is the reference nucleotide? What is the substitution? "],
["transcriptome-quantification.html", "6 Transcriptome Quantification", " 6 Transcriptome Quantification "],
["introduction-rbioconductor.html", "7 Introduction R/Bioconductor 7.1 Start Environment 7.2 Installing packages 7.3 Installation instructions: 7.4 More information 7.5 Grammer of Graphics (ggplot2) 7.6 Reference", " 7 Introduction R/Bioconductor 7.1 Start Environment ## maybe take away the --rm so they can save the container for later ## run from your home directory cd ## example for user99 docker run --rm -it -e PASSWORD=train \\ -v $PWD/Share:/Share \\ -v $PWD:/mydir \\ -p 9099:8787 kdgosik/scellbern2019 Explaination of commands - docker: command to run docker - run: asking docker to run a container - --rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - - this will keep all session output displaying on the terminal - - to stop container go to terminal and press Crtl+c - -v $PWD/Share:/Share: map the share directory from AWS to Share inside docker container - -v $PWD:/mydir: map your home directory to a directory inside docker container called home - -p 9017:8787: map docker container port of 8787(rstudio port default) to your computer port 9017 - kdgosik/scellbern2019: the image to run. It will be the image into a container if not already built on your computer - [image link](https://hub.docker.com/r/kdgosik/scellbern2019) localhost:9099 or on AWS :9099 ec2-.us-west-2.compute.amazonaws.com:$PORT_NUMBER ec2-54-202-32-102.us-west-2.compute.amazonaws.com:9099 R/Rstudio parts Data Types and classes Packages and where to get them S3 vs S4 Visualizations and ggplot Installing packages Data-types Data manipulation, slicing Strings manipulations Introducing object oriented programming / S4 objects Visualization tools Bonus create FeaturePlot from Seurat in base ggplot Bonus: run RSEM on Dana’s bam files if you are bored 7.2 Installing packages 7.2.1 CRAN The Comprehensive R Archive Network CRAN is the biggest archive of R packages. There are few requirements for uploading packages besides building and installing succesfully, hence documentation and support is often minimal and figuring how to use these packages can be a challenge it itself. CRAN is the default repository R will search to find packages to install: install.packages(&quot;devtools&quot;) # or multiple packages install.packages(c(&quot;ggplot2&quot;, &quot;stringr&quot;)) 7.2.2 Github Github isn’t specific to R, any code of any type in any state can be uploaded. There is no guarantee a package uploaded to github will even install, nevermind do what it claims to do. R packages can be downloaded and installed directly from github using the “devtools” package installed above. ## username/repository devtools::install_github(&quot;satijalab/seurat&quot;) # latest stable version of Seurat package Github is also a version control system which stores multiple versions of any package. By default the most recent “master” version of the package is installed. If you want an older version or the development branch this can be specified using the “ref” parameter: # different branch devtools::install_github(&quot;satijalab/seurat&quot;, ref=&quot;release3.0&quot;) # previous commit ## Merge branch &#39;develop&#39; into feat/MultiModal ## - Shiwei Zheng committed on Jul 2, 2018 devtools::install_github(&quot;tallulandrews/M3Drop&quot;, ref=&quot;551014f488770627ab154a62e59d49df5df98a3f&quot;) Note: make sure you re-install the M3Drop master branch for later in the course. 7.2.3 Bioconductor Bioconductor is a repository of R-packages specifically for biological analyses. It has the strictest requirements for submission, including installation on every platform and full documentation with a tutorial (called a vignette) explaining how the package should be used. Bioconductor also encourages utilization of standard data structures/classes and coding style/naming conventions, so that, in theory, packages and analyses can be combined into large pipelines or workflows. Bioconductor also requires creators to support their packages and has a regular 6-month release schedule. Make sure you are using the most recent release of bioconductor before trying to install packages for the course. ## &gt;= R 3.5.0 if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;Rsamtools&quot;, version = &quot;3.8&quot;, ask = FALSE) 7.2.4 Source The final way to install packages is directly from source. In this case you have to download a fully built source code file, usually packagename.tar.gz, or clone the github repository and rebuild the package yourself. Generally this will only be done if you want to edit a package yourself, or if for some reason the former methods have failed. You can also get previous packages that aren’t supported any more on the CRAN package archive ## Get an old package and install from source install.packages(&quot;GenABEL_1.8-0.tar.gz&quot;, type=&quot;source&quot;) 7.3 Installation instructions: All the packages necessary for this course are available here. A list of the packages will be on the README.md for the repository. A script is also available inside the docker/install.R file. 7.3.1 Classes/Types R is a high level language so the underlying data-type is generally not important. The exception if you are accessing R data directly using another language such as C, but that is beyond the scope of this course. Instead we will consider the basic data classes: numeric, integer, logical, and character, and the higher level data class called “factor”. You can check what class your data is using the “class()” function. 7.3.1.1 Integer x &lt;- 4 ## assign value of 4 to x class(x) ## check class of x ## [1] &quot;numeric&quot; is.integer(x) ## check if x is an integer ## [1] FALSE is.numeric(x) ## check if x is numeric ## [1] TRUE x &lt;- as.numeric(x) ## assign y to be an numeric is.numeric(x) ## check if the assignment worked ## [1] TRUE class(x) ## check if the assignment worked ## [1] &quot;numeric&quot; x ## check value of x ## [1] 4 7.3.1.2 Numeric ## assign value of 1.414 to y y &lt;- 1.414 ## check class of y class(y) ## [1] &quot;numeric&quot; ## check if y is numeric is.numeric(y) ## [1] TRUE ## check if y is an integer is.integer(y) ## [1] FALSE ## assign y to be an integer y &lt;- as.integer(y) ## check if the assignment worked is.integer(y) ## [1] TRUE ## check value of y y ## [1] 1 7.3.1.3 Logical/ Boolean The logical class stores boolean truth values, i.e. TRUE and FALSE. It is used for storing the results of logical operations and conditional statements will be coerced to this class. Most other data-types can be coerced to boolean without triggering (or “throwing”) error messages, which may cause unexpected behaviour. z &lt;- TRUE ## assign value of TRUE to z class(z) ## check class of z ## [1] &quot;logical&quot; is.logical(z) ## check if z is of logical type ## [1] TRUE 7.3.2 Data structures Homogeneous 1D: atomic vector 2D: matrix nD: array Heterogeneous 1D: list 2D: data.frame 7.3.2.1 Character Vectors ## assign a character vector with c() operator character_vector &lt;- c(&quot;A&quot;, &quot;C&quot;, &quot;T&quot;, &quot;G&quot;, &quot;C&quot;, &quot;T&quot;, &quot;G&quot;, &quot;C&quot;, &quot;G&quot;, &quot;A&quot;, &quot;T&quot;, &quot;G&quot;, &quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;A&quot;, &quot;C&quot;) ## check class class(character_vector) ## [1] &quot;character&quot; ## access the 3rd element with [] operator ## *note*: R is index starts at 1 (other programming languages start at 0) character_vector[3] ## [1] &quot;T&quot; ## access 3rd through 6th elemenet character_vector[3:6] ## [1] &quot;T&quot; &quot;G&quot; &quot;C&quot; &quot;T&quot; ## access the elements 1,4,7,10 with c() character_vector[c(1, 4, 7, 10)] ## [1] &quot;A&quot; &quot;G&quot; &quot;G&quot; &quot;A&quot; ## access all the A&#39;s character_vector[grep(&quot;A&quot;, character_vector)] ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; 7.3.2.2 Numeric Vector The “numeric” class is the default class for storing any numeric data - integers, decimal numbers, numbers in scientific notation, etc… ## assign a character vector with c() operator numeric_vector &lt;- c(1, 5, 21, 17, 98, 35, 11, 13) ## check class class(numeric_vector) ## [1] &quot;numeric&quot; ## access the 5th element with [] operator numeric_vector[5] ## [1] 98 ## access 2nd through 4th elemenet numeric_vector[2:4] ## [1] 5 21 17 ## backticks ` ` allow you to give names with non-typical characters `numeric?_vecotr` &lt;- c(&quot;A&quot;, 1, 5, 21, 17, 98, 35, 11, 13) ## check vector `numeric?_vecotr` ## [1] &quot;A&quot; &quot;1&quot; &quot;5&quot; &quot;21&quot; &quot;17&quot; &quot;98&quot; &quot;35&quot; &quot;11&quot; &quot;13&quot; ## check class (Notice the quotation marks on the numbers!) class(`numeric?_vecotr`) ## [1] &quot;character&quot; 7.3.2.3 Factor Vector String/Character data is very memory inefficient to store, each letter generally requires the same amount of memory as any integer. Thus when storing a vector of strings with repeated elements it is more efficient assign each element to an integer and store the vector as integers and an additional string-to-integer association table. Thus, by default R will read in text columns of a data table as factors. factor_vector &lt;- factor(numeric_vector) factor_vector ## [1] 1 5 21 17 98 35 11 13 ## Levels: 1 5 11 13 17 21 35 98 7.3.2.4 Named Vector names(numeric_vector) &lt;- paste0(&quot;Patient&quot;, 1 : length(numeric_vector)) numeric_vector ## Patient1 Patient2 Patient3 Patient4 Patient5 Patient6 Patient7 Patient8 ## 1 5 21 17 98 35 11 13 7.3.2.5 List ## change the c() operator to list() operator new_list &lt;- list(&quot;A&quot;, 1, 5, 21, 17, 98, 35, 11, 13) new_list ## [[1]] ## [1] &quot;A&quot; ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] 5 ## ## [[4]] ## [1] 21 ## ## [[5]] ## [1] 17 ## ## [[6]] ## [1] 98 ## ## [[7]] ## [1] 35 ## ## [[8]] ## [1] 11 ## ## [[9]] ## [1] 13 ## get 2nd element of list new_list[[2]] ## [1] 1 names(new_list) &lt;- paste0(&quot;Patient&quot;, 1 : length(new_list)) new_list ## $Patient1 ## [1] &quot;A&quot; ## ## $Patient2 ## [1] 1 ## ## $Patient3 ## [1] 5 ## ## $Patient4 ## [1] 21 ## ## $Patient5 ## [1] 17 ## ## $Patient6 ## [1] 98 ## ## $Patient7 ## [1] 35 ## ## $Patient8 ## [1] 11 ## ## $Patient9 ## [1] 13 ## get 2nd element of list new_list[[2]] ## [1] 1 2D 7.3.2.6 matrix Create Matrix ## create numeric matrix numeric_matrix &lt;- matrix(sample(1:10, 100, replace = TRUE), nrow = 10, ncol = 10) class(numeric_matrix) ## check class ## [1] &quot;matrix&quot; Check Structure str(numeric_matrix) ## int [1:10, 1:10] 6 10 4 9 1 5 1 1 1 10 ... Get 3rd Row ## get 3rd row numeric_matrix[3, ] ## [1] 4 5 8 10 4 10 4 2 4 2 Get 4th Column ## get 4th colum numeric_matrix[, 4] ## [1] 9 10 10 10 10 6 7 1 5 6 7.3.2.7 data.frame Get data.frame ## built in R data.frame iris head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Check Class class(iris) ## [1] &quot;data.frame&quot; Check Structure str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Get 3rd Row ## get 3rd row iris[3,] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 4.7 3.2 1.3 0.2 setosa Get 4th Column ## get 4th colum iris[,4] ## [1] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 ## [18] 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 ## [35] 0.2 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 ## [52] 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 ## [69] 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 ## [86] 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 ## [103] 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 ## [120] 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 ## [137] 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8 Get 3rd Row ## get 3rd row numeric_matrix[3, ] ## [1] 4 5 8 10 4 10 4 2 4 2 Get Species Variable ## get variable iris$Species ## [1] setosa setosa setosa setosa setosa setosa ## [7] setosa setosa setosa setosa setosa setosa ## [13] setosa setosa setosa setosa setosa setosa ## [19] setosa setosa setosa setosa setosa setosa ## [25] setosa setosa setosa setosa setosa setosa ## [31] setosa setosa setosa setosa setosa setosa ## [37] setosa setosa setosa setosa setosa setosa ## [43] setosa setosa setosa setosa setosa setosa ## [49] setosa setosa versicolor versicolor versicolor versicolor ## [55] versicolor versicolor versicolor versicolor versicolor versicolor ## [61] versicolor versicolor versicolor versicolor versicolor versicolor ## [67] versicolor versicolor versicolor versicolor versicolor versicolor ## [73] versicolor versicolor versicolor versicolor versicolor versicolor ## [79] versicolor versicolor versicolor versicolor versicolor versicolor ## [85] versicolor versicolor versicolor versicolor versicolor versicolor ## [91] versicolor versicolor versicolor versicolor versicolor versicolor ## [97] versicolor versicolor versicolor versicolor virginica virginica ## [103] virginica virginica virginica virginica virginica virginica ## [109] virginica virginica virginica virginica virginica virginica ## [115] virginica virginica virginica virginica virginica virginica ## [121] virginica virginica virginica virginica virginica virginica ## [127] virginica virginica virginica virginica virginica virginica ## [133] virginica virginica virginica virginica virginica virginica ## [139] virginica virginica virginica virginica virginica virginica ## [145] virginica virginica virginica virginica virginica virginica ## Levels: setosa versicolor virginica 7.3.3 Detour to S3/S4 S3 most of R uses Bioconductor requires R packages to be written as S4 objects OO field guide Closer to a typical programming language Classes/Methods and Generics Lots of Generics implemented for Bioinformatics! Different way to access values. Need to use the @ symbol instead of $ (@ is equivalent to $, and slot() to [[.) ## example object@ 7.3.3.1 Sparse Matrix Triplet format for storing a matrix row, column, value i, p, x Different from base R. Uses the S4 methods that Bioconductor uses. sparse_matrix &lt;- pbmc_small@data[1:10, ] class(sparse_matrix) ith row - 1 sparse_matrix@i pth column - 1 sparse_matrix@p value sparse_matrix@x Get First Value sparse_matrix[2,1] dense matrix dense_matrix &lt;- as.matrix(sparse_matrix) class(dense_matrix) str(dense_matrix) Get First Value dense_matrix[2,1] 7.3.3.2 Functions create_function &lt;- function(x, y) { } 7.3.3.3 Reading Files ## read csv files read.csv(&quot;PATH/TO/FILENAME.csv&quot;) ## read tsv files read.delim(&quot;PATH/TO/FILENAME.tsv&quot;, sep = &#39;\\t&#39;) 7.4 More information You can get more information about any R commands relevant to these datatypes using by typing ?function in an interactive session. 7.4.1 Checking for help for any function! start with a ? (this indicates you need the help menu) then the function name to get help on library(ggplot2) ?ggplot ## ggplot is a function, how do we use it? 7.5 Grammer of Graphics (ggplot2) 7.5.1 What is ggplot2? ggplot2 is an R package designed by Hadley Wickham which facilitates data plotting. In this lab, we will touch briefly on some of the features of the package. If you would like to learn more about how to use ggplot2, we would recommend reading “ggplot2 Elegant graphics for data analysis”, by Hadley Wickham or checking out his original paper on the package Data: Always start with the data, identify the dimensions you want to visualize. Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions. Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range? Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on? Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals? Facets: Do we need to create subplots based on specific data dimensions? Coordinate system: What kind of a coordinate system should the visualization be based on — should it be cartesian or polar? 7.5.2 Principles of ggplot2 Your data must be a dataframe if you want to plot it using ggplot2. Use the aes mapping function to specify how variables in the dataframe map to features on your plot Use geoms to specify how your data should be represented on your graph eg. as a scatterplot, a barplot, a boxplot etc. Data: Always start with the data, identify the dimensions you want to visualize. library(Seurat) library(ggplot2) gbm &lt;- pbmc_small@assays$RNA@data gbm &lt;- as.data.frame(as.matrix(t(gbm))) new_plot &lt;- ggplot(gbm) Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions. 1D Plots new_plot_1dx &lt;- ggplot(gbm, aes(x = MS4A1)) new_plot_1dx Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range? Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on? ## ggplot(gbm, aes(x = MS4A1)) + geom_histogram() ## or ## new_plot_1dx &lt;- new_plot_1dx + geom_histogram() ## reassign new_plot_1dx + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 7.5.2.1 Lab A Use different geom_ to make a different plots - try _bar() - try _density() new_plot_1dx + geom_density() Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals? ggplot(gbm, aes(x = MS4A1)) + geom_histogram() + stat_bin(bins = 10) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 2D Plots new_plot_2d &lt;- ggplot(gbm, aes(x = MS4A1, y = CD79B)) ## scatter plot new_plot_2d + geom_point() 7.5.2.2 Lab B Use different geom_ to make a different plots - try _bar_abline() - try _bin2d() new_plot_2d Adding Statisitics in 2D plots Regression line (lm - linear model using OLS regression) ggplot(gbm, aes(MS4A1, CD79B)) + geom_point() + stat_smooth(method = &quot;lm&quot;) Adding Text Labels ## notice plus `+` at the end of each line, adding a new layer! ggplot(gbm, aes(MS4A1, CD79B)) + ## Data layer geom_point() + ## Geometry layer stat_smooth(method = &quot;lm&quot;) + ## geom_text(aes(label = rownames(gbm))) 7.5.2.3 Lab C Play arund with ggplot2. See what geoms to add and layers to include. ggplot(gbm, aes(x = MS4A1, y = CD79B)) 7.6 Reference R for Data Science Advanced R Bioconductor Workflows Bioconductor Presentation Original ggplot2 paper ggplot2 reference ggplot2 cheatsheet blog post Hemberg Lab "],
["expression-qc-and-normalization.html", "8 Expression QC and Normalization", " 8 Expression QC and Normalization "],
["data-wrangling-scrnaseq.html", "9 Data Wrangling scRNAseq 9.1 Goal 9.2 Introduction 9.3 Filtering low-quality cells 9.4 Beginning with Seurat: http://satijalab.org/seurat/ 9.5 Preprocessing step 1 : Filter out low-quality cells 9.6 Examine contents of Seurat object 9.7 Detection of variable genes across the single cells 9.8 Gene set expression across cells", " 9 Data Wrangling scRNAseq 9.1 Goal To give you experience with the analysis of single cell RNA sequencing (scRNA-seq) including performing quality control and identifying cell type subsets. To introduce you to scRNA-seq analysis using the Seurat package. 9.2 Introduction Data produced in a single cell RNA-seq experiment has several interesting characteristics that make it distinct from data produced in a bulk population RNA-seq experiment. Two characteristics that are important to keep in mind when working with scRNA-Seq are drop-out (the excessive amount of zeros due to limiting mRNA) and the potential for quality control (QC) metrics to be confounded with biology. This combined with the ability to measure heterogeniety from cells in samples has shifted the field away from the typical analysis in population-based RNA-Seq. Here we demonstrate some approaches to quality control, followed by identifying and analyzing cell subsets. For this tutorial, we will be analyzing the a dataset of Non-Small Cell Lung Cancer Cells (NSCLC) freely available from 10X Genomics (https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex), using the Seurat R package (http://satijalab.org/seurat/), a popular and powerful set of tools to conduct scRNA-seq analysis in R. In this dataset, there are 7802 single cells that were sequenced on the Illumina NovaSeq 6000. Please note this tutorial borrows heavily from Seurat’s tutorials, so feel free to go through them in more detail. 9.2.1 Load necessary packages When loading libraries, we are asking R to load code for us written by someone else. It is a convenient way to leverage and reproduce methodology developed by others. library(Seurat) library(dplyr) library(Matrix) library(gdata) 9.2.2 Read in NSCLC counts matrix. The data for Non-Small Cell Lung Cancer Cells (NSCLC) is freely available from 10X Genomics (https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex). We start by reading in the counts matrix generated by the Cell Ranger count program. Task: Change the directory name to mydir/ where you saved your data dirname &lt;- &quot;/mydir/Lab08-Data-Wrangling-scRNAseq/&quot; counts_matrix_filename = paste0(dirname,&quot;/filtered_gene_bc_matrices/GRCh38/&quot;) counts &lt;- Read10X(data.dir = counts_matrix_filename) # Seurat function to read in 10x count data # To minimize memory use on the docker - choose only the first 1000 cells counts &lt;- counts[,1:1000] 9.2.3 Let’s examine the sparse counts matrix counts[1:10, 1:3] Here we see the upper left corner of the sparse matrix. The columns are indexed by 10x cell barcodes (each 16 nt long), and the rows are the gene names. We mentioned these matrices are sparse, here we see only zeroes (indicated by the “.” symbol); this is the most common value in these sparse matrices. Next, let us look at the dimensions of this matrix. 9.2.4 How big is the matrix? dim(counts) # report number of genes (rows) and number of cells (columns) Here we see the counts matrix has 33694 genes and 7802 cells. 9.2.5 How much memory does a sparse matrix take up relative to a dense matrix? object.size(counts) # size in bytes object.size(as.matrix(counts)) # size in bytes We see here that the sparse matrix takes 225 Mb in memory while storing the matrix in a dense format (where all count values including zeros are stored) takes almost 10 times as much memory! This memory saving is very important, especially as data sets are now being created that are beyond a million cells. These matrices can become unmanageable without special computing resources. In the sparse representation, we assume that the majority of count values in a matrix are zero. We only store the non-zero values. This is implemented in the Matrix package using a dgTMatrix object. 9.3 Filtering low-quality cells You can learn a lot about your scRNA-seq data’s quality with simple plotting. Let’s do some plotting to look at the number of reads per cell, reads per genes, expressed genes per cell (often called complexity), and rarity of genes (cells expressing genes). 9.3.1 Look at the summary counts for genes and cells counts_per_cell &lt;- Matrix::colSums(counts) counts_per_gene &lt;- Matrix::rowSums(counts) genes_per_cell &lt;- Matrix::colSums(counts&gt;0) # count gene only if it has non-zero reads mapped. Task: In a similar way, can you calculate cells per genes? replace the ‘?’ in the command below #### cells_per_gene &lt;- Matrix::?(counts&gt;?) # only count cells where the gene is expressed cells_per_gene &lt;- Matrix::rowSums(counts&gt;0) # only count cells where the gene is expressed colSums and rowSums are functions that work on each row or column in a matrix and return the column sums or row sums as a vector. If this is true counts_per_cell should have 1 entry per cell. Let’s make sure the length of the returned vector matches the matrix dimension for column. How would you do that? ( Hint:length() ). Notes: 1. Matrix::colSums is a way to force functions from the Matrix library to be used. There are many libraries that implement colSums, we are forcing the one from the Matrix library to be used here to make sure it handles the dgTmatrix (sparse matrix) correctly. This is good practice. hist(log10(counts_per_cell+1),main=&#39;counts per cell&#39;,col=&#39;wheat&#39;) hist(log10(genes_per_cell+1), main=&#39;genes per cell&#39;, col=&#39;wheat&#39;) plot(counts_per_cell, genes_per_cell, log=&#39;xy&#39;, col=&#39;wheat&#39;) title(&#39;counts vs genes per cell&#39;) Here we see examples of plotting a new plot, the histogram. R makes this really easy with the hist function. We are also transforming the values to log10 before plotting, this is done with the log10 method. When logging count data, the + 1 is used to avoid log10(0) which is not defined. Can you a histogram of counts per gene in log10 scale? hist(log10(counts_per_gene+1), main=&#39;counts per gene&#39;, col=&#39;wheat&#39;) ### hist(?(?+1), main=&#39;counts per gene&#39;, col=&#39;wheat&#39;) 9.3.2 Plot cells ranked by their number of detected genes. Here we rank each cell by its library complexity, ie the number of genes detected per cell. This is a very useful plot as it shows the distribution of library complexity in the sequencing run. One can use this plot to investigate observations (potential cells) that are actually failed libraries (lower end outliers) or observations that are cell doublets (higher end outliers). plot(sort(genes_per_cell), xlab=&#39;cell&#39;, log=&#39;y&#39;, main=&#39;genes per cell (ordered)&#39;) 9.4 Beginning with Seurat: http://satijalab.org/seurat/ 9.4.1 Creating a seurat object To analyze our single cell data we will use a seurat object. Can you create an Seurat object with the 10x data and save it in an object called ‘seurat’? hint: CreateSeuratObject(). Can you include only genes that are are expressed in 3 or more cells and cells with complexity of 350 genes or more? How many genes are you left with? How many cells? ### seurat&lt;-CreateSeuratObject(raw.data = counts, ? = 3, ? = 350, project = &quot;10X_NSCLC&quot;) seurat&lt;-CreateSeuratObject(raw.data = counts, min.cells = 3, min.genes = 350, project = &quot;10X_NSCLC&quot;) Almost all our analysis will be on the single object, of class Seurat. This object contains various “slots” (designated by seurat@slotname) that will store not only the raw count data, but also the results from various computations below. This has the advantage that we do not need to keep track of inidividual variables of interest - they can all be collapsed into a single object as long as these slots are pre-defined. seurat@raw.data is a slot that stores the original gene count matrix. We can view the first 10 rows (genes) and the first 10 columns (cells). seurat@raw.data[1:10,1:10] 9.5 Preprocessing step 1 : Filter out low-quality cells The Seurat object initialization step above only considered cells that expressed at least 350 genes. Additionally, we would like to exclude cells that are damaged. A common metric to judge this (although by no means the only one) is the relative expression of mitochondrially derived genes. When the cells apoptose due to stress, their mitochondria becomes leaky and there is widespread RNA degradation. Thus a relative enrichment of mitochondrially derived genes can be a tell-tale sign of cell stress. Here, we compute the proportion of transcripts that are of mitochondrial origin for every cell (percent.mito), and visualize its distribution as a violin plot. We also use the GenePlot function to observe how percent.mito correlates with other metrics. # The number of genes and UMIs (nGene and nUMI) are automatically calculated for every object by Seurat. For non-UMI # data, nUMI represents the sum of the non-normalized values within a cell We calculate the percentage of mitochondrial # genes here and store it in percent.mito using AddMetaData. We use object@raw.data since this represents # non-transformed and non-log-normalized counts The % of UMI mapping to MT-genes is a common scRNA-seq QC metric. mito.genes &lt;- grep(pattern = &quot;^MT-&quot;, x = rownames(x = seurat@data), value = TRUE) percent.mito &lt;- Matrix::colSums(seurat@raw.data[mito.genes, ])/Matrix::colSums(seurat@raw.data) # AddMetaData adds columns to object@meta.data, and is a great place to stash QC stats. This also allows us to plot the # metadata values using the Seurat&#39;s VlnPlot(). head(seurat@meta.data) # Before adding Task: Can add the percentage if mitochondrial genes to the seurat object meta data? If you dont remember the name of the parameter you can type ?AddMetaData in the console. #### seurat &lt;- AddMetaData(object = seurat, ? = ?, col.name = &quot;percent.mito&quot;) seurat &lt;- AddMetaData(object = seurat, metadata = percent.mito, col.name = &quot;percent.mito&quot;) head(seurat@meta.data) # After adding VlnPlot(object = seurat, features.plot = c(&quot;nGene&quot;, &quot;nUMI&quot;, &quot;percent.mito&quot;), nCol = 3, point.size.use = 0.1) Here we calculated the percent mitochondrial reads and added it to the Seurat object in the slot named meta.data. This allowed us to plot using the violin plot function provided by Seurat. A third metric we use is the number of house keeping genes expressed in a cell. These genes reflect commomn processes active in a cell and hence are a good global quality measure. They are also abundant and are usually steadliy expressed in cells, thus less sensitive to the high dropout. # Load the the list of house keeping genes hkgenes &lt;- read.table(paste0(dirname,&quot;/tirosh_house_keeping.txt&quot;), skip = 2) hkgenes &lt;- as.vector(hkgenes$V1) # remove hkgenes that were not found hkgenes.found &lt;- which(toupper(rownames(seurat@data)) %in% hkgenes) Possible task: Feel like challenging yourself? write the code to do the following: 1. Sum the number of detected house keeping genes for each cell 2. Add this information as meta data to seurat 3. plot all metrics: “nGene”, “nUMI”, “percent.mito”,“n.exp.hkgenes” using VlnPlot 4. Scroll down to see if you got it! If you feel like going through a more guided version, scroll down and follow the instructions. Alternative task: Sum the number of detected house keeping genes for each cell, then add this to the meta data #### n.expressed.hkgenes &lt;- ?(seurat@data[hkgenes.found, ] &gt; ?) #### seurat &lt;- AddMetaData(object = ?, ? = ?, col.name = &quot;n.exp.hkgenes&quot;) n.expressed.hkgenes &lt;- Matrix::colSums(seurat@data[hkgenes.found, ] &gt; 0) seurat &lt;- AddMetaData(object = seurat, metadata = n.expressed.hkgenes, col.name = &quot;n.exp.hkgenes&quot;) VlnPlot(object = seurat, features.plot = c(&quot;nGene&quot;, &quot;nUMI&quot;, &quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), nCol = 4, point.size.use = 0.1) Is there a correlation between the measurements? For example, number of UMIs with number of genes? Possible task: Feel like challenging yourself? write the code to do the following: Can you plot the nGene vs nUMI (hint:GenePlot)? What is the correlation? Do you see a strange subpopulation? What do you think happened with these cells? seurat Scroll down to see the command Alternative task: Can you plot the nGene vs nUMI (hint:GenePlot)? What is the correlation? Do you see a strange subpopulation? What do you think happened with these cells? ### GenePlot(object = seurat, gene1 = ?, gene2 = ?) GenePlot(object = seurat, gene1 = &quot;nUMI&quot;, gene2 = &quot;nGene&quot;) 9.6 Examine contents of Seurat object str(seurat) These are the slots in the Seurat object. Some of the slots are automatically updated by Seurat as you move through analysis. Take a moment to look through the information, knowing the slots allow you to leverage work Seurat has already done for you. VlnPlot(object = seurat, features.plot = c(&quot;nGene&quot;), group.by = c(&#39;orig.ident&#39;)) Here we plot the number of genes per cell by what Seurat calls orig.ident. Identity is a concept that is used in the Seurat object to refer to the cell identity. In this case, the cell identity is 10X_NSCLC, but after we cluster the cells, the cell identity will be whatever cluster the cell belongs to. We will see how identity updates as we go throught the analysis. Next, let’s filter the cells based on the quality control metrics. Filter based on: 1. nGene 2. percent.mito 3. n.exp.hkgenes Task: Change the thresholds to what you think they should be according to the violin plots VlnPlot(object = seurat, features.plot = c(&quot;nGene&quot;,&quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), nCol = 3, point.size.use = 0.1) #### seurat &lt;- FilterCells(object = seurat, subset.names = c(&quot;nGene&quot;, &quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), low.thresholds = c(350, -Inf,55), high.thresholds = c(5000, 0.1, Inf)) How many cells are you left with? seurat 9.6.1 Preprocessing step 2 : Expression normalization After removing unwanted genes cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. There have been many methods to normalize the data, but this is the simplest and the most intuitive. The division by total expression is done to change all expression counts to a relative measure, since experience has suggested that technical factors (e.g. capture rate, efficiency of reverse transcription) are largely responsible for the variation in the number of molecules per cell, although genuine biological factors (e.g. cell cycle stage, cell size) also play a smaller, but non-negligible role. The log-transformation is a commonly used transformation that has many desirable properties, such as variance stabilization (can you think of others?). seurat &lt;- NormalizeData(object = seurat, normalization.method = &quot;LogNormalize&quot;, scale.factor = 1e4) Well there you have it! A filtered and normalized gene-expression data set. A great accomplishment for your first dive into scRNA-Seq analysis. Well done! 9.7 Detection of variable genes across the single cells Seurat calculates highly variable genes and focuses on these for downstream analysis. FindVariableGenes calculates the average expression and dispersion for each gene, places these genes into bins, and then calculates a z-score for dispersion within each bin. This helps control for the relationship between variability and average expression. This function is unchanged from (Macosko et al.), but new methods for variable gene expression identification are coming soon. We suggest that users set these parameters to mark visual outliers on the dispersion plot, but the exact parameter settings may vary based on the data type, heterogeneity in the sample, and normalization strategy. The parameters here identify ~3,000 variable genes, and represent typical parameter settings for UMI data that is normalized to a total of 1e4 molecules. #seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5, num.bin=20) # if this fails, experiment with the num.bin setting seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 1, y.cutoff = 0.5, num.bin=20) # if this fails, experiment with the num.bin setting length(seurat@var.genes) We can see the Seurat object slots have updated for the FindVariableGenes section. Let’s use the slot to see how many variable genes we found. str(seurat) length(x = seurat@var.genes) Task: how does changing the parameters for find variable genes function changes the number of the found genes? Play with the parameters - what makes the function find more variable genes? less? seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 1, y.cutoff = 0.5, num.bin=40, do.plot = FALSE) length(seurat@var.genes) seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 1, y.cutoff = 0.5, num.bin=10, do.plot = FALSE) length(seurat@var.genes) seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 1, y.cutoff = 0.5, num.bin=20, do.plot = FALSE) length(seurat@var.genes) seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.2, x.high.cutoff = 1, y.cutoff = 0.5, num.bin=20, do.plot = FALSE) length(seurat@var.genes) seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 0.1, y.cutoff = 0.5, num.bin=20, do.plot = FALSE) length(seurat@var.genes) seurat &lt;- FindVariableGenes(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.0125, x.high.cutoff = 1, y.cutoff = 2, num.bin=10, do.plot = FALSE) length(seurat@var.genes) 9.8 Gene set expression across cells Sometimes we want to ask what is the expression of a set of a genes across cells. This set of genes may make up a gene expression program we are interested in. Another benefit at looking at gene sets is it reduces the effects of drop outs. Below, we look at genes involved in: T cells, the cell cycle and the stress signature upon cell dissociation. We calculate these genes average expression levels on the single cell level, while controlling for technical effects. # Read in a list of cell cycle markers, from Tirosh et al, 2015. # We can segregate this list into markers of G2/M phase and markers of S phase. cc.genes &lt;- readLines(paste0(dirname,&quot;/regev_lab_cell_cycle_genes.txt&quot;)) s.genes &lt;- cc.genes[1:43] g2m.genes &lt;- cc.genes[44:97] seurat &lt;- CellCycleScoring(object = seurat, s.genes = s.genes, g2m.genes = g2m.genes, set.ident = T) Task: Use markers for dissociation to calculate dissociation score # Genes upregulated during dissociation of tissue into single cells. genes.dissoc &lt;- c(&quot;ATF3&quot;, &quot;BTG2&quot;, &quot;CEBPB&quot;, &quot;CEBPD&quot;, &quot;CXCL3&quot;, &quot;CXCL2&quot;, &quot;CXCL1&quot;, &quot;DNAJA1&quot;, &quot;DNAJB1&quot;, &quot;DUSP1&quot;, &quot;EGR1&quot;, &quot;FOS&quot;, &quot;FOSB&quot;, &quot;HSP90AA1&quot;, &quot;HSP90AB1&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA8&quot;, &quot;HSPB1&quot;, &quot;HSPE1&quot;, &quot;HSPH1&quot;, &quot;ID3&quot;, &quot;IER2&quot;, &quot;JUN&quot;, &quot;JUNB&quot;, &quot;JUND&quot;, &quot;MT1X&quot;, &quot;NFKBIA&quot;, &quot;NR4A1&quot;, &quot;PPP1R15A&quot;, &quot;SOCS3&quot;, &quot;ZFP36&quot;) #### seurat &lt;- ?(?, genes.list = list(?), ctrl.size = 20, enrich.name = &quot;genes_dissoc&quot;) seurat &lt;- AddModuleScore(seurat, genes.list = list(genes.dissoc), ctrl.size = 20, enrich.name = &quot;genes_dissoc&quot;) Task: Plot the correlation between number of genes and S score. How do we know the name of these scores in the seurat meta data? ### GenePlot(seurat, &quot;S.Score&quot;, &quot;nGene&quot;) GenePlot(seurat, &quot;S.Score&quot;, &quot;nGene&quot;) Bonus: Can you cluster the data based on the variable genes alone? Congratulations! You can identify and visualize cell subsets and the marker genes that describe these cell subsets. This is a very powerful analysis pattern often seen in publications. Well done! "],
["identifying-cell-populations.html", "10 Identifying Cell Populations 10.1 Google Slides", " 10 Identifying Cell Populations 10.1 Google Slides "],
["feature-selection-and-cluster-analysis.html", "11 Feature Selection and Cluster Analysis 11.1 Abstract 11.2 Seurat Tutorial 11.3 Feature Selection", " 11 Feature Selection and Cluster Analysis 11.1 Abstract Many methods have been used to determine differential gene expression from single-cell RNA (scRNA)-seq data. We evaluated 36 approaches using experimental and synthetic data and found considerable differences in the number and characteristics of the genes that are called differentially expressed. Prefiltering of lowly expressed genes has important effects, particularly for some of the methods developed for bulk RNA-seq data analysis. However, we found that bulk RNA-seq analysis methods do not generally perform worse than those developed specifically for scRNA-seq. We also present conquer, a repository of consistently processed, analysis-ready public scRNA-seq data sets that is aimed at simplifying method evaluation and reanalysis of published results. Each data set provides abundance estimates for both genes and transcripts, as well as quality control and exploratory analysis reports. (Soneson and Robinson 2018) Cells are the basic building blocks of organisms and each cell is unique. Single-cell RNA sequencing has emerged as an indispensable tool to dissect the cellular heterogeneity and decompose tissues into cell types and/or cell states, which offers enormous potential for de novo discovery. Single-cell transcriptomic atlases provide unprecedented resolution to reveal complex cellular events and deepen our understanding of biological systems. In this review, we summarize and compare single-cell RNA sequencing technologies, that were developed since 2009, to facilitate a well-informed choice of method. The applications of these methods in different biological contexts are also discussed. We anticipate an ever-increasing role of single-cell RNA sequencing in biology with further improvement in providing spatial information and coupling to other cellular modalities. In the future, such biological findings will greatly benefit medical research. (Hedlund and Deng 2018) 11.2 Seurat Tutorial library(Seurat) library(dplyr) library(ggplot2) library(CountClust) pbmc &lt;- pbmc_small pbmc@meta.data$barcode &lt;- row.names(pbmc@meta.data) # pbmc@ident &lt;- factor() 11.2.1 Preprocessing Steps This was all covered in the last Lab! # The number of genes and UMIs (nGene and nUMI) are automatically calculated # for every object by Seurat. For non-UMI data, nUMI represents the sum of # the non-normalized values within a cell We calculate the percentage of # mitochondrial genes here and store it in percent.mito using AddMetaData. # We use object@raw.data since this represents non-transformed and # non-log-normalized counts The % of UMI mapping to MT-genes is a common # scRNA-seq QC metric. mito.genes &lt;- grep(pattern = &quot;^MT-&quot;, x = rownames(x = pbmc@data), value = TRUE) percent.mito &lt;- Matrix::colSums(pbmc@raw.data[mito.genes, ])/Matrix::colSums(pbmc@raw.data) # AddMetaData adds columns to object@meta.data, and is a great place to # stash QC stats pbmc &lt;- AddMetaData(object = pbmc, metadata = percent.mito, col.name = &quot;percent.mito&quot;) ##VlnPlot(object = pbmc, features.plot = c(&quot;nGene&quot;, &quot;nUMI&quot;), &quot;percent.mito&quot;), nCol = 3) # GenePlot is typically used to visualize gene-gene relationships, but can # be used for anything calculated by the object, i.e. columns in # object@meta.data, PC scores etc. Since there is a rare subset of cells # with an outlier level of high mitochondrial percentage and also low UMI # content, we filter these as well par(mfrow = c(1, 2)) GenePlot(object = pbmc, gene1 = &quot;nUMI&quot;, gene2 = &quot;percent.mito&quot;) GenePlot(object = pbmc, gene1 = &quot;nUMI&quot;, gene2 = &quot;nGene&quot;) Already A Subset of the Data This is not run becuase we are already working with a subset. This is here for reference. # We filter out cells that have unique gene counts over 2,500 or less than # 200 Note that low.thresholds and high.thresholds are used to define a # &#39;gate&#39;. -Inf and Inf should be used if you don&#39;t want a lower or upper # threshold. pbmc &lt;- FilterCells(object = pbmc, subset.names = c(&quot;nGene&quot;, &quot;percent.mito&quot;), low.thresholds = c(200, -Inf), high.thresholds = c(2500, 0.1)) pbmc &lt;- NormalizeData(object = pbmc, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) pbmc &lt;- FindVariableGenes(object = pbmc, mean.function = ExpMean, dispersion.function = LogVMR, do.plot = FALSE) 11.2.2 Start of Identifying Cell Types 11.2.2.1 Scaling This part is where you mean center the data, substract the mean. You also divide by the standard deviation to make everything to a ‘standard normal’, where the mean is zero and the standard deviation is 1. pbmc &lt;- ScaleData(object = pbmc, vars.to.regress = c(&quot;batch&quot;, &quot;percent.mito&quot;)) Try Regressing Other Variables ## batch_ids &lt;- read.csv(&#39;file_with_batch_ids.csv&#39;) ## randomly making a batch id data.frame batch_ids &lt;- data.frame(barcode = rownames(pbmc@meta.data), batch_id = sample(0:2, 80, replace = TRUE), stringsAsFactors = FALSE) row.names(batch_ids) &lt;- row.names(pbmc@meta.data) pbmc &lt;- AddMetaData(object = pbmc, metadata = batch_ids, col.name = &quot;batch_id&quot;) pbmc &lt;- ScaleData(object = pbmc, vars.to.regress = &#39;batch_id&#39;) 11.2.2.2 Running PCA This will run pca on the pbmc &lt;- RunPCA(object = pbmc, pc.genes = pbmc@var.genes, do.print = TRUE, pcs.print = 1:5, genes.print = 5) 11.2.2.3 Running ICA Try running Independent Component Analysis. If you need help with the inputs try using the ?RunICA menu. pbmc &lt;- RunICA(pbmc, ics.compute=5) 11.2.2.4 Visualizing PCA in Different Ways VizPCA(object = pbmc, pcs.use = 1:2) 11.2.2.5 Visualizing ICA in Different Ways VizICA(object = pbmc, ics.use=1:3) PCAPlot(object = pbmc, dim.1 = 1, dim.2 = 2) # ProjectPCA scores each gene in the dataset (including genes not included # in the PCA) based on their correlation with the calculated components. # Though we don&#39;t use this further here, it can be used to identify markers # that are strongly correlated with cellular heterogeneity, but may not have # passed through variable gene selection. The results of the projected PCA # can be explored by setting use.full=T in the functions above pbmc &lt;- ProjectPCA(object = pbmc, do.print = FALSE) 11.2.2.6 Genes by PCs PCHeatmap(object = pbmc, pc.use = 1:10, cells.use = 50, do.balanced = TRUE, label.columns = FALSE) Check other PCs to plot PCHeatmap() PCElbowPlot(object = pbmc, num.pc = 10) # save.SNN = T saves the SNN so that the clustering algorithm can be rerun # using the same graph but with a different resolution value (see docs for # full details) set.seed(2019) pbmc &lt;- FindClusters(object = pbmc, reduction.type = &quot;pca&quot;, dims.use = 1:10, resolution = 1, print.output = 0) set.seed(runif(100)) pbmc &lt;-RunTSNE(pbmc, reduction.use = &quot;pca&quot;, dims.use = 1:10, perplexity=10) # note that you can set do.label=T to help label individual clusters TSNEPlot(object = pbmc) # find all markers of cluster 1 cluster1.markers &lt;- FindMarkers(object = pbmc, ident.1 = 1, min.pct = 0.25) print(x = head(x = cluster1.markers, n = 5)) # find all markers distinguishing cluster 2 from clusters 0 and 1 cluster2.markers &lt;- FindMarkers(object = pbmc, ident.1 = 2, ident.2 = c(0, 1), min.pct = 0.25) print(x = head(x = cluster5.markers, n = 5)) # find markers for every cluster compared to all remaining cells, report # only the positive ones pbmc.markers &lt;- FindAllMarkers(object = pbmc, only.pos = TRUE, min.pct = 0.25, thresh.use = 0.25) pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(2, avg_logFC) 11.2.2.7 Find Marker Genes cluster1.markers &lt;- FindMarkers(object = pbmc, ident.1 = 0, thresh.use = 0.25, test.use = &quot;roc&quot;, only.pos = TRUE) VlnPlot(object = pbmc, features.plot = c(&quot;MS4A1&quot;, &quot;CD79A&quot;)) # you can plot raw UMI counts as well VlnPlot(object = pbmc, features.plot = c(&quot;NKG7&quot;, &quot;PF4&quot;), use.raw = TRUE, y.log = TRUE) FeaturePlot(object = pbmc, features.plot = c(&quot;MS4A1&quot;, &quot;GNLY&quot;, &quot;CD3E&quot;, &quot;CD14&quot;, &quot;FCER1A&quot;, &quot;FCGR3A&quot;, &quot;LYZ&quot;, &quot;PPBP&quot;, &quot;CD8A&quot;), cols.use = c(&quot;grey&quot;, &quot;blue&quot;), sreduction.use = &quot;tsne&quot;) top10 &lt;- pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(10, avg_logFC) # setting slim.col.label to TRUE will print just the cluster IDS instead of # every cell name DoHeatmap(object = pbmc, genes.use = top10$gene, slim.col.label = TRUE, remove.key = TRUE) current.cluster.ids &lt;- c(0, 1, 2, 3, 4, 5, 6, 7) new.cluster.ids &lt;- c(&quot;CD4 T cells&quot;, &quot;CD14+ Monocytes&quot;, &quot;B cells&quot;, &quot;CD8 T cells&quot;, &quot;FCGR3A+ Monocytes&quot;, &quot;NK cells&quot;, &quot;Dendritic cells&quot;, &quot;Megakaryocytes&quot;) pbmc@ident &lt;- plyr::mapvalues(x = pbmc@ident, from = current.cluster.ids, to = new.cluster.ids) TSNEPlot(object = pbmc, do.label = TRUE, pt.size = 0.5) 11.2.2.8 Further subdivisions within cell types If you perturb some of our parameter choices above (for example, setting resolution=0.8 or changing the number of PCs), you might see the CD4 T cells subdivide into two groups. You can explore this subdivision to find markers separating the two T cell subsets. However, before reclustering (which will overwrite object@ident), we can stash our renamed identities to be easily recovered later. # First lets stash our identities for later pbmc &lt;- StashIdent(object = pbmc, save.name = &quot;ClusterNames_0.6&quot;) # Note that if you set save.snn=T above, you don&#39;t need to recalculate the # SNN, and can simply put: pbmc &lt;- FindClusters(pbmc,resolution = 0.8) pbmc &lt;- FindClusters(object = pbmc, reduction.type = &quot;pca&quot;, dims.use = 1:10, resolution = 0.8, print.output = FALSE) ## Warning in BuildSNN(object = object, genes.use = genes.use, reduction.type ## = reduction.type, : Build parameters exactly match those of already ## computed and stored SNN. To force recalculation, set force.recalc to TRUE. # Demonstration of how to plot two tSNE plots side by side, and how to color # points based on different criteria plot1 &lt;- TSNEPlot(object = pbmc, do.return = TRUE, no.legend = TRUE, do.label = TRUE) plot2 &lt;- TSNEPlot(object = pbmc, do.return = TRUE, group.by = &quot;ClusterNames_0.6&quot;, no.legend = TRUE, do.label = TRUE) plot_grid(plot1, plot2) # Find discriminating markers tcell.markers &lt;- FindMarkers(object = pbmc, ident.1 = 0, ident.2 = 1) # Most of the markers tend to be expressed in C1 (i.e. S100A4). However, we # can see that CCR7 is upregulated in C0, strongly indicating that we can # differentiate memory from naive CD4 cells. cols.use demarcates the color # palette from low to high expression FeaturePlot(object = pbmc, features.plot = c(&quot;S100A4&quot;, &quot;CCR7&quot;), cols.use = c(&quot;green&quot;, &quot;blue&quot;)) 11.3 Feature Selection 11.3.1 Differential Expression Analysis 11.3.1.1 Differential Expression Tests One of the most commonly performed tasks for RNA-seq data is differential gene expression (DE) analysis. Although well- established tools exist for such analysis in bulk RNA-seq data6–8, methods for scRNA-seq data are just emerging. Given the special characteristics of scRNA-seq data, including generally low library sizes, high noise levels and a large fraction of so-called ‘dropout’ events, it is unclear whether DE methods that have been devel- oped for bulk RNA-seq are suitable also for scRNA-seq ## Differential expression using DESeq2 DESeq2DETest(object = pbmc, cells.1, cells.2, genes.use = NULL, assay.type = &quot;RNA&quot;) ## Likelihood ratio test for zero-inflated data DiffExpTest(object = pbmc, cells.1, cells.2, assay.type = &quot;RNA&quot;, genes.use = NULL, print.bar = TRUE) ## t-test DiffTTest(object = pbmc, cells.1, cells.2, genes.use = NULL, print.bar = TRUE, assay.type = &quot;RNA&quot;) 11.3.2 Dimensionality Reduction 11.3.2.1 Principal Components Analysis (PCA) RunPCA() 11.3.3 Independent Components Analysis (ICA) RunICA() 11.3.4 Clustering 11.3.4.1 Kmeans DoKMeans(object, genes.use = NULL, k.genes = NULL, k.cells = 0, k.seed = 1, do.plot = FALSE, data.cut = 2.5, k.cols = PurpleAndYellow(), set.ident = TRUE, do.constrained = FALSE, assay.type = &quot;RNA&quot;, ...) 11.3.4.2 Louvain ## Neighborhood graph BuildSNN(object, genes.use = NULL, reduction.type = &quot;pca&quot;, dims.use = NULL, k.param = 10, plot.SNN = FALSE, prune.SNN = 1/15, print.output = TRUE, distance.matrix = NULL, force.recalc = FALSE, filename = NULL, save.SNN = TRUE, nn.eps = 0) FindClusters(object, genes.use = NULL, reduction.type = &quot;pca&quot;, dims.use = NULL, k.param = 30, plot.SNN = FALSE, prune.SNN = 1/15, print.output = TRUE, distance.matrix = NULL, save.SNN = FALSE, reuse.SNN = FALSE, force.recalc = FALSE, nn.eps = 0, modularity.fxn = 1, resolution = 0.8, algorithm = 1, n.start = 100, n.iter = 10, random.seed = 0, temp.file.location = NULL, edge.file.name = NULL) 11.3.4.3 Probabilistic (LDA) set.seed(2019) ## Set Cluster Identity to the clustering using a resolution of 1 (res.1) SetIdent(pbmc_small, ident.use = &#39;res.1&#39;) pbmc_counts &lt;- as.matrix(pbmc_small@data) pbmc_meta &lt;- pbmc_small@meta.data gene_names &lt;- rownames(pbmc_counts) pbmc_FitGoM &lt;- FitGoM(t(pbmc_counts), K=4) omega &lt;- pbmc_FitGoM$fit$omega annotation &lt;- data.frame(sample_id = rownames(omega), tissue_label = paste0(&quot;topic&quot;, 1:4)) colnames(omega) &lt;- paste0(&quot;topic&quot;, 1:4) rownames(omega) &lt;- annotation$sample_id; StructureGGplot(omega = omega, annotation = annotation, palette = RColorBrewer::brewer.pal(4, &quot;Dark2&quot;), yaxis_label = &quot;Cells&quot;, order_sample = TRUE, axis_tick = list(axis_ticks_length = .1, axis_ticks_lwd_y = .1, axis_ticks_lwd_x = .1, axis_label_size = 7, axis_label_face = &quot;bold&quot;)) ## Add Topic Scores to Meta Data Part of the Seurat Object pbmc_small@meta.data &lt;- cbind(pbmc_meta, omega) pbmc_small@meta.data %&gt;% group_by(res.1) %&gt;% summarise(topic1 = mean(topic1), topic2 = mean(topic2), topic3 = mean(topic3), topic4 = mean(topic4)) ## ggplot object, you can add layers p1 &lt;- TSNEPlot(pbmc_small, do.return = TRUE) + labs(title = &quot;Resolution 1&quot;) ## return ggplot object p1 p2 &lt;- FeaturePlot(object = pbmc_small, features.plot = c(&quot;topic1&quot;, &quot;topic2&quot;, &quot;topic3&quot;, &quot;topic4&quot;), cols.use = c(&quot;grey&quot;, &quot;blue&quot;), reduction.use = &quot;tsne&quot;, do.return = TRUE) ## return ggplot object p2 plot_grid(p1, p2) class(p2) plot_grid(p1, p2[[1]], p2[[2]], p2[[3]], p2[[4]]) 11.3.4.4 Extract Top Feature theta_mat &lt;- pbmc_FitGoM$fit$theta top_features &lt;- ExtractTopFeatures(theta_mat, top_features=100, method=&quot;poisson&quot;, options=&quot;min&quot;) gene_list &lt;- do.call(rbind, lapply(1:dim(top_features$indices)[1], function(x) gene_names[top_features$indices[x,]])) We tabulate the top \\(5\\) genes for these \\(6\\) clusters. tmp &lt;- do.call(rbind, lapply(1:5, function(i) toString(gene_list[,i]))) rownames(tmp) &lt;- paste(&quot;Cluster&quot;, c(1:5)) tmp %&gt;% kable(&quot;html&quot;) %&gt;% kable_styling() 11.3.5 Check Clusters Use Classifier to predict cell cluster. See how it predicts using hold out data. test.pbmc &lt;- SubsetData(object = pbmc_small, cells.use = pbmc_small@cell.names[1:10]) train.pbmc &lt;- SubsetData(object = pbmc_small, cells.use = pbmc_small@cell.names[11:80]) predicted.classes &lt;- ClassifyCells( object = train.pbmc, training.classes = train.pbmc@ident, new.data = test.pbmc@data ) table(predicted.classes, test.pbmc@ident) Visually check by comparing centroids of clusters in gene space and embedding space. pmbc_small &lt;- GetCentroids(pbmc_small, cells.use=pbmc_small@cell.names) 11.3.6 Practice Visualizing/Embedding 11.3.6.1 tSNE Change the parameter settings for tSNE RunTSNE() 11.3.6.2 UMAP Change the parameter settings for UMAP RunUMAP() References "],
["batch-effects.html", "12 Batch Effects", " 12 Batch Effects "],
["correcting-batch-effects.html", "13 Correcting Batch Effects 13.1 Load settings and packages 13.2 Preparing the individual Seurat objects for each pancreas dataset without batch correction 13.3 Cluster pancreatic datasets without batch correction 13.4 Additional exploration: Regressing out unwanted covariates 13.5 Additional exploration: kBET 13.6 Additional exploration: Seurat 3 13.7 Acknowledgements", " 13 Correcting Batch Effects In this lab, we will look at different single cell RNA-seq datasets collected from pancreatic islets. We will look at how different batch correction methods affect our data analysis. Note: you can increase the system memory available to Docker by going to Docker -&gt; Preferences -&gt; Advanced and shifting the Memory slider. 13.1 Load settings and packages 13.2 Preparing the individual Seurat objects for each pancreas dataset without batch correction # What is the size of each single cell RNA-seq dataset? # Briefly describe the technology used to collect each dataset. # Which datasets do you expect to be different and which do you expect to be similar? dim(celseq.data) dim(celseq2.data) dim(fluidigmc1.data) dim(smartseq2.data) # Create and setup Seurat objects for each dataset with the following 6 steps. # 1. CreateSeuratObject # 2. FilterCells # 3. NormalizeData # 4. FindVariableGenes # 5. ScaleData # 6. Update @meta.data slot in Seurat object with tech column (celseq, celseq2, fluidigmc1, smartseq2) # Look at the distributions of number of genes per cell before and after FilterCells. # CEL-seq (https://www.cell.com/cell-reports/fulltext/S2211-1247(12)00228-8) # In FilterCells, use low.thresholds = 1750 celseq &lt;- CreateSeuratObject(counts = celseq.data) VlnPlot(celseq, &quot;nGene&quot;) celseq &lt;- FilterCells(celseq, subset.names = &quot;nGene&quot;, low.thresholds = 1750) VlnPlot(celseq, &quot;nGene&quot;) celseq &lt;- NormalizeData(celseq) celseq &lt;- FindVariableGenes(celseq, do.plot = F, display.progress = F) celseq &lt;- ScaleData(celseq) celseq@meta.data$tech &lt;- &quot;celseq&quot; # CEL-Seq2 https://www.cell.com/molecular-cell/fulltext/S1097-2765(09)00641-8 # In FilterCells, use low.thresholds = 2500. celseq2 &lt;- CreateSeuratObject(counts = celseq2.data) VlnPlot(celseq2, &quot;nGene&quot;) celseq2 &lt;- FilterCells(celseq2, subset.names = &quot;nGene&quot;, low.thresholds = 2500) VlnPlot(celseq2, &quot;nGene&quot;) celseq2 &lt;- NormalizeData(celseq2) celseq2 &lt;- FindVariableGenes(celseq2, do.plot = F, display.progress = F) celseq2 &lt;- ScaleData(celseq2) celseq2@meta.data$tech &lt;- &quot;celseq2&quot; # Fluidigm C1 # Omit FilterCells function call because cells are already high quality. fluidigmc1 &lt;- CreateSeuratObject(counts = fluidigmc1.data) VlnPlot(fluidigmc1, &quot;nGene&quot;) fluidigmc1 &lt;- NormalizeData(fluidigmc1) fluidigmc1 &lt;- FindVariableGenes(fluidigmc1, do.plot = F, display.progress = F) fluidigmc1 &lt;- ScaleData(fluidigmc1) fluidigmc1@meta.data$tech &lt;- &quot;fluidigmc1&quot; # SMART-Seq2 # In FilterCells, use low.thresholds = 2500. smartseq2 &lt;- CreateSeuratObject(counts = smartseq2.data) VlnPlot(smartseq2, &quot;nGene&quot;) smartseq2 &lt;- FilterCells(smartseq2, subset.names = &quot;nGene&quot;, low.thresholds = 2500) VlnPlot(smartseq2, &quot;nGene&quot;) smartseq2 &lt;- NormalizeData(smartseq2) smartseq2 &lt;- FindVariableGenes(smartseq2, do.plot = F, display.progress = F) smartseq2 &lt;- ScaleData(smartseq2) smartseq2@meta.data$tech &lt;- &quot;smartseq2&quot; # This code sub-samples the data in order to speed up calculations and not use too much memory. celseq &lt;- SetAllIdent(celseq, id = &quot;tech&quot;) celseq &lt;- SubsetData(celseq, max.cells.per.ident = 500, random.seed = 1) celseq2 &lt;- SetAllIdent(celseq2, id = &quot;tech&quot;) celseq2 &lt;- SubsetData(celseq2, max.cells.per.ident = 500, random.seed = 1) fluidigmc1 &lt;- SetAllIdent(fluidigmc1, id = &quot;tech&quot;) fluidigmc1 &lt;- SubsetData(fluidigmc1, max.cells.per.ident = 500, random.seed = 1) smartseq2 &lt;- SetAllIdent(smartseq2, id = &quot;tech&quot;) smartseq2 &lt;- SubsetData(smartseq2, max.cells.per.ident = 500, random.seed = 1) # Save the sub-sampled Seurat objects # save(celseq, celseq2, fluidigmc1, smartseq2, file = Rda.sparse.path) 13.3 Cluster pancreatic datasets without batch correction Let us cluster all the pancreatic islet datasets together and see whether there is a batch effect. # Merge Seurat objects by making a list of the 4 Seurat objects and using MergeMultipleSeuratObjects. # The documentation for this function is in the first code chunk. gcdata &lt;- MergeMultipleSeuratObjects(list(&quot;celseq&quot; = celseq, &quot;celseq2&quot; = celseq2, &quot;fluidigmc1&quot; = fluidigmc1, &quot;smartseq2&quot; = smartseq2), project = &quot;pancreas&quot;) # Look at how the number of cells per gene varies across the different technologies. VlnPlot(gcdata, &quot;nGene&quot;, group.by = &quot;tech&quot;) # The merged data must be normalized and scaled (but you only need to scale the variable genes). # Let us also find the variable genes again this time using all the pancreas data. gcdata &lt;- NormalizeData(object = gcdata) gcdata &lt;- FindVariableGenes(gcdata, do.plot = F, display.progress = F) gcdata &lt;- ScaleData(gcdata, genes.use = gcdata@var.genes) # Do PCA on data including only the variable genes. gcdata &lt;- RunPCA(gcdata, pc.genes = gcdata@var.genes, pcs.compute = 30, do.print = TRUE, pcs.print = 5, genes.print = 5) # Color the PC biplot by the scRNA-seq technology. Hint: use DimPlot # Which technologies look similar to one another? DimPlot(gcdata, reduction.use = &quot;pca&quot;, dim.1 = 1, dim.2 = 2, group.by = &quot;tech&quot;) # Cluster the cells using the first twenty principal components. gcdata &lt;- FindClusters(gcdata, reduction.type = &quot;pca&quot;, dims.use = 1:20, print.output = F, save.SNN = T, force.recalc = T, random.seed = 100) # Create a tSNE visualization. gcdata &lt;- RunTSNE(gcdata, dims.use = 1:20, do.fast = T, reduction.use = &quot;pca&quot;, perplexity = 30) # Visualize the Louvain clustering and the batches on the tSNE. # Remember, the clustering is stored in @meta.data in column res.0.8 and the technology is # stored in the column tech. Remember you can also use DimPlot DimPlot(gcdata, reduction.use = &quot;tsne&quot;, dim.1 = 1, dim.2 = 2, group.by = &quot;res.0.8&quot;) DimPlot(gcdata, reduction.use = &quot;tsne&quot;, dim.1 = 1, dim.2 = 2, group.by = &quot;tech&quot;) # Are you surprised by the results? Compare to your expectations from the PC biplot. # Adjusted rand index test for overlap between technology and cluster labelings. # This goes between 0 (completely dissimilar clustering) to 1 (identical clustering). # The adjustment corrects for chance grouping between cluster elements. # https://davetang.org/muse/2017/09/21/adjusted-rand-index/ ari &lt;- dplyr::select(gcdata@meta.data, tech, res.0.8) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$res.0.8)) # Save current progress. # save(gcdata, file = Rda.path) # To load the data, run the following command. # load(Rda.path) 13.3.1 Batch correction: canonical correlation analysis (CCA) using Seurat Here we use canonical correlation analysis to see to what extent it can remove potential batch effects. # The first piece of code will identify variable genes that are highly variable in at least 2/4 datasets. We will use these variable genes in our batch correction. # Why would we implement such a requirement? ob.list &lt;- list(celseq, celseq2, fluidigmc1, smartseq2) genes.use &lt;- c() for (i in 1:length(ob.list)) { genes.use &lt;- c(genes.use, head(rownames(ob.list[[i]]@hvg.info), 1000)) } genes.use &lt;- names(which(table(genes.use) &gt; 1)) for (i in 1:length(ob.list)) { genes.use &lt;- genes.use[genes.use %in% rownames(ob.list[[i]]@scale.data)] } # Run multi-set CCA on the 4 pancreatic islet datasets. # Use the variable genes above, and calculate 15 canonical components. gcdata.CCA &lt;- RunMultiCCA(ob.list, genes.use = genes.use, num.ccs = 15) # Visualize CCA results. First plot CC1 versus CC2 with cells grouped by tech. DimPlot(gcdata.CCA, reduction.use = &quot;cca&quot;, group.by = &quot;tech&quot;, pt.size = 0.5) # Visualize CCA results. Second, look at a violin plot of CC1 scores with cells grouped by tech. VlnPlot(gcdata.CCA, features.plot = c(&quot;CC1&quot;, &quot;CC2&quot;), group.by = &quot;tech&quot;) # We can also look at the genes important in the first few canonical components. DimHeatmap(object = gcdata.CCA, reduction.type = &quot;cca&quot;, cells.use = 500, dim.use = 1:9, do.balanced = TRUE) # Read the documentation for MetageneBicorPlot and # also read https://en.wikipedia.org/wiki/Biweight_midcorrelation # Use this function to determine how many canonical components to select. # Remember to use the appropriate grouping variable. # Try evaluating the first 15 canonical components. MetageneBicorPlot(gcdata.CCA, grouping.var = &quot;tech&quot;, dims.eval = 1:15) # Based on the previous heatmaps and the midcorrelation plot, how many CCs will you select? # Next we can align the CCA subspaces across the 4 datasets. This will generate a new # dimensional reduction called cca.aligned. The cells from all the datasets can then # be clustered in this new space. # Use AlignSubspace, specifying which variable to group by and the number of CCs to align gcdata.CCA &lt;- AlignSubspace(gcdata.CCA, grouping.var = &quot;tech&quot;, dims.align = 1:12) # Visualize the distribution of the aligned canonical correlation vectors (ACC1, ACC2) # using VlnPlot. VlnPlot(gcdata.CCA, features.plot = &quot;ACC1&quot;, group.by = &quot;tech&quot;) VlnPlot(gcdata.CCA, features.plot = &quot;ACC2&quot;, group.by = &quot;orig.ident&quot;, do.return = TRUE) # How does this compare to the distributions of the canonical components (CC1, CC2)? # Clustering. Choose the dimensional reduction type to use and the number of aligned # canonical correlation vectors to use. gcdata.CCA &lt;- FindClusters(gcdata.CCA, reduction.type = &quot;cca.aligned&quot;, dims.use = 1:12, save.SNN = T, random.seed = 100) # tSNE. Choose the dimensional reduction type to use and the number of aligned # canonical correlation vectors to use. gcdata.CCA &lt;- RunTSNE(gcdata.CCA, reduction.use = &quot;cca.aligned&quot;, dims.use = 1:12, do.fast = TRUE, seed.use = 1) # gcdata.CCA &lt;- RunTNSE() # Visualize the Louvain clustering and the batches on the tSNE. # Remember, the clustering is stored in @meta.data in column res.0.8 and the technology is # stored in the column tech. Remember you can also use DimPlot p1 &lt;- DimPlot(gcdata.CCA, reduction.use = &quot;tsne&quot;, dim.1 = 1, dim.2 = 2, group.by = &quot;res.0.8&quot;, do.return = T) p2 &lt;- DimPlot(gcdata.CCA, reduction.use = &quot;tsne&quot;, dim.1 = 1, dim.2 = 2, group.by = &quot;tech&quot;, do.return = T) plot_grid(p1, p2) # Let&#39;s look to see how the adjusted rand index changed compared to using no batch correction. ari &lt;- dplyr::select(gcdata.CCA@meta.data, tech, res.0.8) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$res.0.8)) # We can also identify conserved marker genes across the batches. Differential gene expression is # done across each batch, and the p-values are combined. markers &lt;- FindConservedMarkers(gcdata.CCA, ident.1 = 0, grouping.var = &quot;tech&quot;, print.bar = T) head(markers) # Visualize the expression of the first 5 marker genes on tSNE across the different batches # using FeatureHeatmap. FeatureHeatmap(gcdata.CCA, features.plot = rownames(markers)[1:5], group.by = &quot;tech&quot;, pt.size = 0.25, key.position = &quot;top&quot;, max.exp = 3) # Save current progress. # save(gcdata.CCA, file = Rda.CCA.path) # To load the data, run the following command. # load(Rda.CCA.path) 13.3.2 Batch correction: integrative non-negative matrix factorization (NMF) using LIGER Here we use integrative non-negative matrix factorization to see to what extent it can remove potential batch effects. The important parameters in the batch correction are the number of factors (k), the penalty parameter (lambda), and the clustering resolution. The number of factors sets the number of factors (consisting of shared and dataset-specific factors) used in factorizing the matrix. The penalty parameter sets the balance between factors shared across the batches and factors specific to the individual batches. The default setting of lambda=5.0 is usually used by the Macosko lab. Resolution=1.0 is used in the Louvain clustering of the shared neighbor factors that have been quantile normalized. # The first piece of code will identify variable genes that are highly variable in at least 2/4 datasets. We will use these variable genes in our batch correction. ob.list &lt;- list(celseq, celseq2, fluidigmc1, smartseq2) genes.use &lt;- c() for (i in 1:length(ob.list)) { genes.use &lt;- c(genes.use, head(rownames(ob.list[[i]]@hvg.info), 1000)) } genes.use &lt;- names(which(table(genes.use) &gt; 1)) for (i in 1:length(ob.list)) { genes.use &lt;- genes.use[genes.use %in% rownames(ob.list[[i]]@scale.data)] } # Next we create a LIGER object with raw counts data from each batch. ob.list &lt;- list(&quot;celseq&quot; = celseq.data, &quot;celseq2&quot; = celseq2.data, &quot;fluidigmc1&quot; = fluidigmc1.data, &quot;smartseq2&quot; = smartseq2.data) data.liger &lt;- createLiger(ob.list) # Normalize gene expression for each batch. data.liger &lt;- liger::normalize(data.liger) # For variable gene selection, we can either use those we identified in the earlier CCA # batch correction analysis (genes.use) or we can use the LIGER function selectGenes(). # data.liger &lt;- selectGenes(data.liger, var.thresh = 0.1) data.liger@var.genes &lt;- genes.use # Print out the number of variable genes for LIGER analysis. print(length(data.liger@var.genes)) # Scale the gene expression across the datasets. # Why does LIGER not center the data? Hint, think about the use of # non-negative matrix factorization and the constraints that this imposes. data.liger &lt;- scaleNotCenter(data.liger) # These two steps take 10-20 min. Only run them if you finish with the rest of the code. # Use the `suggestK` function to determine the appropriate number of factors to use. # Use the `suggestLambda` function to find the smallest lambda for which the alignment metric stabilizes. # suggestK(data.liger) # suggestLambda(ligerex, k = 20) # Use alternating least squares (ALS) to factorize the matrix. k.suggest &lt;- 20 # with this line, we do not use the suggested k by suggestK() data.liger &lt;- optimizeALS(data.liger, k = k.suggest, rand.seed = 1) # What do matrices H, V, and W represent, and what are their dimensions? dim(data.liger@H$celseq) dim(data.liger@V$celseq) dim(data.liger@W) # Let&#39;s see what the integrated data looks like mapped onto a tSNE visualization. data.liger &lt;- runTSNE(data.liger, use.raw = T) p &lt;- plotByDatasetAndCluster(data.liger, return.plots = T) print(p[[1]]) # plot by dataset # Next, do clustering of cells in shared nearest factor space, and then quantile alignment. data.liger &lt;- quantileAlignSNF(data.liger, resolution = 1.0) # SNF clustering and quantile alignment # What are the dimensions of H.norm. What does this represent? dim(data.liger@H.norm) # Visualize liger batch correction results. data.liger &lt;- runTSNE(data.liger) p &lt;- plotByDatasetAndCluster(data.liger, return.plots = T) print(p[[1]]) # plot by dataset plot_grid(p[[1]], p[[2]]) # Let&#39;s look to see how the adjusted rand index changed compared to using no batch correction. tech &lt;- unlist(lapply(1:length(data.liger@H), function(x) { rep(names(data.liger@H)[x], nrow(data.liger@H[[x]]))})) clusters &lt;- data.liger@alignment.clusters ari &lt;- data.frame(&quot;tech&quot; = tech, &quot;clusters&quot; = clusters) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$clusters)) # Look at proportion of each batch in each cluster, and look at factor loadings across clusters plotClusterProportions(data.liger) plotClusterFactors(data.liger, use.aligned = T) # Look at genes that are specific to a dataset and shared across datasets. # Use the plotWordClouds function and choose 2 datasets. pdf(paste0(mydir, &quot;word_clouds.pdf&quot;)) plotWordClouds(data.liger, dataset1 = &quot;celseq2&quot;, dataset2 = &quot;smartseq2&quot;) dev.off() # Look at factor loadings for each cell using plotFactors. pdf(paste0(mydir, &quot;plot_factors.pdf&quot;)) plotFactors(data.liger) dev.off() # Identify shared and batch-specific marker genes from liger factorization. # Use the getFactorMarkers function and choose 2 datasets. # Then plot some genes of interest using plotGene and plotGeneViolin. markers &lt;- getFactorMarkers(data.liger, dataset1 = &quot;celseq2&quot;, dataset2 = &quot;smartseq2&quot;, num.genes = 10) plotGene(data.liger, gene = &quot;INS&quot;) plotGeneViolin(data.liger, gene = &quot;INS&quot;) # Save current progress. # save(data.liger, file = Rda.liger.path) # To load the data, run the following command. # load(Rda.liger.path) 13.4 Additional exploration: Regressing out unwanted covariates Learn how to regress out different technical covariates (number of UMIs, number of genes, percent mitochondrial reads) by studying Seurat’s PBMC tutorial and the ScaleData() function. 13.5 Additional exploration: kBET Within your RStudio session, install k-nearest neighbour batch effect test and learn how to use its functionality to quantify batch effects in the pancreatic data. 13.6 Additional exploration: Seurat 3 Read how new version of Seurat does data integration 13.7 Acknowledgements This document builds off a tutorial from the Seurat website and a tutorial from the LIGER website. "],
["functional-analysis.html", "14 Functional Analysis 14.1 Google Slides 14.2 Gene sets and signatures 14.3 Pathway analysis 14.4 inferCNV / honeybadger", " 14 Functional Analysis 14.1 Google Slides 14.2 Gene sets and signatures 14.2.1 Cell Cycle marrow &lt;- CellCycleScoring(object = marrow, s.genes = s.genes, g2m.genes = g2m.genes, set.ident = TRUE) # view cell cycle scores and phase assignments head(x = marrow@meta.data) # Visualize the distribution of cell cycle markers across RidgePlot(object = marrow, features.plot = c(&quot;PCNA&quot;, &quot;TOP2A&quot;, &quot;MCM6&quot;, &quot;MKI67&quot;), nCol = 2) # Running a PCA on cell cycle genes reveals, unsurprisingly, that cells # separate entirely by phase marrow &lt;- RunPCA(object = marrow, pc.genes = c(s.genes, g2m.genes), do.print = FALSE) PCAPlot(object = marrow) 14.3 Pathway analysis 14.4 inferCNV / honeybadger Github Page 14.4.1 Create the InferCNV Object Reading in the raw counts matrix and meta data, populating the infercnv object infercnv_obj = CreateInfercnvObject( raw_counts_matrix=&quot;../example/oligodendroglioma_expression_downsampled.counts.matrix&quot;, annotations_file=&quot;../example/oligodendroglioma_annotations_downsampled.txt&quot;, delim=&quot;\\t&quot;, gene_order_file=&quot;../example/gencode_downsampled.txt&quot;, ref_group_names=c(&quot;Microglia/Macrophage&quot;,&quot;Oligodendrocytes (non-malignant)&quot;)) 14.4.2 Filtering genes Removing those genes that are very lowly expressed or present in very few cells # filter out low expressed genes cutoff=1 infercnv_obj &lt;- require_above_min_mean_expr_cutoff(infercnv_obj, cutoff) # filter out bad cells min_cells_per_gene=3 infercnv_obj &lt;- require_above_min_cells_ref(infercnv_obj, min_cells_per_gene=min_cells_per_gene) ## for safe keeping infercnv_orig_filtered = infercnv_obj #plot_mean_chr_expr_lineplot(infercnv_obj) save(&#39;infercnv_obj&#39;, file = &#39;../example_output/infercnv_obj.orig_filtered&#39;) 14.4.3 Normalize each cell’s counts for sequencing depth infercnv_obj &lt;- infercnv:::normalize_counts_by_seq_depth(infercnv_obj) 14.4.4 Perform Anscombe normalization Suggested by Matan for removing noisy variation at low counts infercnv_obj &lt;- infercnv:::anscombe_transform(infercnv_obj) 14.4.5 Log transform the normalized counts: infercnv_obj &lt;- log2xplus1(infercnv_obj) 14.4.6 Apply maximum bounds to the expression data to reduce outlier effects threshold = mean(abs(get_average_bounds(infercnv_obj))) infercnv_obj &lt;- apply_max_threshold_bounds(infercnv_obj, threshold=threshold) 14.4.7 Initial view, before inferCNV operations: plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.logtransf&#39;, x.range=&quot;auto&quot;, title = &quot;Before InferCNV (filtered &amp; log2 transformed)&quot;, color_safe_pal = FALSE, x.center = mean(infercnv_obj@expr.data)) 14.4.8 Perform smoothing across chromosomes infercnv_obj = smooth_by_chromosome(infercnv_obj, window_length=101, smooth_ends=TRUE) # re-center each cell infercnv_obj &lt;- center_cell_expr_across_chromosome(infercnv_obj, method = &quot;median&quot;) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.chr_smoothed&#39;, x.range=&quot;auto&quot;, title = &quot;chr smoothed and cells re-centered&quot;, color_safe_pal = FALSE) 14.4.9 Subtract the reference values from observations, now have log(fold change) values infercnv_obj &lt;- subtract_ref_expr_from_obs(infercnv_obj, inv_log=TRUE) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.ref_subtracted&#39;, x.range=&quot;auto&quot;, title=&quot;ref subtracted&quot;, color_safe_pal = FALSE) 14.4.10 Invert log values Converting the log(FC) values to regular fold change values, centered at 1 (no fold change) This is important because we want (1/2)x to be symmetrical to 1.5x, representing loss/gain of one chromosome region. infercnv_obj &lt;- invert_log2(infercnv_obj) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.inverted&#39;, color_safe_pal = FALSE, x.range=&quot;auto&quot;, x.center=1, title = &quot;inverted log FC to FC&quot;) 14.4.11 Removing noise infercnv_obj &lt;- clear_noise_via_ref_mean_sd(infercnv_obj, sd_amplifier = 1.5) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.denoised&#39;, x.range=&quot;auto&quot;, x.center=1, title=&quot;denoised&quot;, color_safe_pal = FALSE) 14.4.12 Remove outlier data points This generally improves on the visualization infercnv_obj = remove_outliers_norm(infercnv_obj) plot_cnv(infercnv_obj, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.outliers_removed&#39;, color_safe_pal = FALSE, x.range=&quot;auto&quot;, x.center=1, title = &quot;outliers removed&quot;) 14.4.13 Find DE genes by comparing the mutant types to normal types, BASIC Runs a t-Test comparing tumor/normal for each patient and normal sample, and masks out those genes that are not significantly DE. plot_data = infercnv_obj@expr.data high_threshold = max(abs(quantile(plot_data[plot_data != 0], c(0.05, 0.95)))) low_threshold = -1 * high_threshold infercnv_obj2 &lt;- infercnv:::mask_non_DE_genes_basic(infercnv_obj, test.use = &#39;t&#39;, center_val=1) plot_cnv(infercnv_obj2, out_dir=&#39;../example_output/&#39;, output_filename=&#39;infercnv.non-DE-genes-masked&#39;, color_safe_pal = FALSE, x.range=c(low_threshold, high_threshold), x.center=1, title = &quot;non-DE-genes-masked&quot;) 14.4.14 Additional Information 14.4.14.1 Online Documentation For additional explanations on files, usage, and a tutorial please visit the wiki. 14.4.14.2 TrinityCTAT This tool is a part of the TrinityCTAT toolkit focused on leveraging the use of RNA-Seq to better understand cancer transcriptomes. To find out more please visit TrinityCTAT 14.4.14.3 Applications This methodology was used in: Anoop P. Patel et al. Single-cell RNA-seq highlights intratumoral heterogeneity in primary glioblastoma. Science. 2014 Jun 20: 1396-1401 Tirosh I et al.Dissecting the multicellular ecosystem of metastatic melanoma by single-cell RNA-seq. Science. 2016 Apr 8;352(6282):189-96 "],
["pseudotime-cell-trajectories.html", "15 Pseudotime Cell Trajectories 15.1 Google Slides 15.2 Comparison Abstract", " 15 Pseudotime Cell Trajectories Comparison: Cell Trajectories Diffusion maps for high-dimensional single-cellanalysis Diffusion pseudotime Slingshot Paper Optimal Transport RNA Velocity 15.1 Google Slides 15.2 Comparison Abstract Using single-cell -omics data, it is now possible to computationally order cells along trajectories, allowing the unbiased study of cellular dynamic processes. Since 2014, more than 50 trajectory inference methods have been developed, each with its own set of methodological characteristics. As a result, choosing a method to infer trajectories is often challenging, since a comprehensive assessment of the performance and robustness of each method is still lacking. In order to facilitate the comparison of the results of these methods to each other and to a gold standard, we developed a global framework to benchmark trajectory inference tools. Using this framework, we compared the trajectories from a total of 29 trajectory inference methods, on a large collection of real and synthetic datasets. We evaluate methods using several metrics, including accuracy of the inferred ordering, correctness of the network topology, code quality and user friendliness. We found that some methods, including Slingshot (Street et al. 2018), TSCAN (Z. Ji and Ji 2016) and Monocle DDRTree (Trapnell et al. 2014), clearly outperform other methods, although their performance depended on the type of trajectory present in the data. Based on our benchmarking results, we therefore developed a set of guidelines for method users. However, our analysis also indicated that there is still a lot of room for improvement, especially for methods detecting complex trajectory topologies. Our evaluation pipeline can therefore be used to spearhead the development of new scalable and more accurate methods, and is available at github.com/dynverse/dynverse. (Saelens et al. 2018) (Haghverdi, Buettner, and Theis 2015) (Haghverdi et al. 2016) (Street et al. 2018) (Schiebinger et al. 2019) (La Manno et al. 2018) knitr::include_graphics(&quot;images/PseudotimeComparisonGuidelines.png&quot;) References "],
["functional-pseudotime-analysis.html", "16 Functional Pseudotime Analysis 16.1 Load settings and packages 16.2 First look at the differentiation data from Deng et al. 16.3 Diffusion map pseudotime 16.4 Slingshot map pseudotime 16.5 Find temporally expressed genes 16.6 Comparison of the different trajectory inference methods 16.7 Plots of gene expression over time. 16.8 Acknowledgements", " 16 Functional Pseudotime Analysis In this lab, we will analyze a single cell RNA-seq dataset that will teach us about several methods to infer the differentiation trajectory of a set of cells. These methods can order a set of individual cells along a path / trajectory / lineage, and assign a pseudotime value to each cell that represents where the cell is along that path. This can be a starting point for further analysis to determine gene expression programs driving interesting cell phenotypes. As you are running the code, think about how the algorithms work and what you like and do not like about the assumptions and utilities provided by the algorithm. Note: you can increase the system memory available to Docker by going to Docker -&gt; Preferences -&gt; Advanced and shifting the Memory slider. 16.1 Load settings and packages 16.2 First look at the differentiation data from Deng et al. We will use a nice SMART-Seq2 single cell RNA-seq data from Single-Cell RNA-Seq Reveals Dynamic, Random Monoallelic Gene Expression in Mammalian Cells. Here is one relevant detail from their paper: “To investigate allele-specific gene expression at single-cell resolution, we isolated 269 individual cells dissociated from in vivo F1 embryos (CAST/EiJ × C57BL/6J, hereafter abbreviated as CAST and C57, respectively) from oocyte to blastocyst stages of mouse preimplantation development (PD)” Let us take a first look at the Deng data. One simple approach to ordering cells in pseudotime is to use PCA. By carrying out PCA and labeling the cells by the stage at which they were collected, we can see how well the principal components separate cells along a differentiation trajectory. # Read in single cell data. path.deng &lt;- paste0(mydir, &quot;deng-reads.rds&quot;) deng_SCE &lt;- readRDS(path.deng) # What class is the deng_SCE object, and how is it organized? class(deng_SCE) ## [1] &quot;SingleCellExperiment&quot; ## attr(,&quot;package&quot;) ## [1] &quot;SingleCellExperiment&quot; structure(deng_SCE) ## class: SingleCellExperiment ## dim: 22431 268 ## metadata(0): ## assays(2): counts logcounts ## rownames(22431): Hvcn1 Gbp7 ... Sox5 Alg11 ## rowData names(10): feature_symbol is_feature_control ... ## total_counts log10_total_counts ## colnames(268): 16cell 16cell.1 ... zy.2 zy.3 ## colData names(30): cell_type2 cell_type1 ... pct_counts_ERCC ## is_cell_control ## reducedDimNames(0): ## spikeNames(1): ERCC # How many mouse cells are at each stage? table(deng_SCE$cell_type1) ## ## 16cell 2cell 4cell 8cell blast zygote ## 50 22 14 37 133 12 table(deng_SCE$cell_type2) ## ## 16cell 4cell 8cell early2cell earlyblast late2cell ## 50 14 37 8 43 10 ## lateblast mid2cell midblast zy ## 30 12 60 4 # Re-order the levels of the factor storing the cell developmental stage. deng_SCE$cell_type2 &lt;- factor(deng_SCE$cell_type2, levels = c(&quot;zy&quot;, &quot;early2cell&quot;, &quot;mid2cell&quot;, &quot;late2cell&quot;, &quot;4cell&quot;, &quot;8cell&quot;, &quot;16cell&quot;, &quot;earlyblast&quot;, &quot;midblast&quot;, &quot;lateblast&quot;)) # Run PCA on Deng data. Use the runPCA function from the SingleCellExperiment package. deng_SCE &lt;- runPCA(deng_SCE, ncomponents = 50) # Use the reducedDim function to access the PCA and store the results. pca &lt;- reducedDim(deng_SCE, &quot;PCA&quot;) # Describe how the PCA is stored in a matrix. Why does it have this structure? head(pca) ## PC1 PC2 PC3 PC4 PC5 PC6 ## 16cell -4.616718 -13.67367 1.6860222 -0.3971110 0.4331834 -3.3351871 ## 16cell.1 -5.528782 -11.18717 2.9383081 0.2381910 0.1644197 -0.8666549 ## 16cell.2 -5.067554 -13.50145 1.6200888 -1.4489428 -0.3560664 -2.7057527 ## 16cell.3 -5.604999 -12.42408 1.2092483 0.7560287 -0.9812613 0.1008600 ## 16cell.4 -4.989056 -12.64989 0.9518061 2.0114694 2.1210373 -0.5469395 ## 16cell.5 -4.605128 -13.35725 1.2909256 -0.6736846 2.1882002 -2.7699870 ## PC7 PC8 PC9 PC10 PC11 PC12 ## 16cell -0.6236209 0.3621665 -1.2910579 2.386634 -1.824875 0.4400858 ## 16cell.1 -0.4232062 -1.0859542 -2.0577693 2.566871 -2.663335 -3.2087906 ## 16cell.2 1.7515857 0.1552950 -1.5951345 1.879552 -3.237261 -0.9710867 ## 16cell.3 1.0103357 -0.4448119 -0.6081911 -1.059523 -4.416895 -0.7229430 ## 16cell.4 0.0563789 -0.7070924 -1.2665595 2.733815 -1.090173 -0.7688942 ## 16cell.5 0.9010465 1.0445247 -2.8906108 2.886413 -1.844421 -4.2520016 ## PC13 PC14 PC15 PC16 PC17 ## 16cell -0.77758746 2.11643418 -0.8244988 0.4831872 -0.8213527 ## 16cell.1 1.95567784 -1.12330816 -2.0169080 2.0721840 0.4924598 ## 16cell.2 1.77982275 0.02196743 -2.0566764 2.1791387 -1.8205026 ## 16cell.3 1.82741705 -2.96140322 -2.0898322 -1.8926069 -1.2088311 ## 16cell.4 0.01732681 -0.77442110 -2.4652798 2.6683790 -1.0930128 ## 16cell.5 1.26660076 -0.08437871 -1.9085246 0.8621796 -0.2821138 ## PC18 PC19 PC20 PC21 PC22 ## 16cell 2.912998472 -0.1114755 0.6633269 -0.88984647 2.73819461 ## 16cell.1 1.555585976 -1.1341038 -2.4003738 -1.00116216 2.79983998 ## 16cell.2 1.544638100 0.2775379 -1.2832673 -0.46297320 0.08161412 ## 16cell.3 -1.164002801 0.8564781 -1.0032480 -0.02165817 2.81656780 ## 16cell.4 0.492283751 0.1123406 0.6449514 -1.48016504 1.69637235 ## 16cell.5 -0.004085098 0.9727746 -0.8545002 -0.82326712 -0.49085584 ## PC23 PC24 PC25 PC26 PC27 ## 16cell -1.2833723 0.26093070 -0.9025236 -0.9199517 0.7705592 ## 16cell.1 -2.0626007 -1.49145200 -0.3073604 -1.6213086 -0.4668769 ## 16cell.2 -0.6273122 -0.82463839 -0.3514344 -0.9143962 0.1285442 ## 16cell.3 1.1540990 1.64935692 -2.8926707 0.5279823 1.0364766 ## 16cell.4 1.3036491 -0.04931057 -1.8065901 -2.3286922 0.7928030 ## 16cell.5 -2.4572424 0.28548367 0.9919387 -1.3399723 -0.4663864 ## PC28 PC29 PC30 PC31 PC32 ## 16cell -1.1942837 3.3616090 -0.8339894 -2.6264466 0.2088315099 ## 16cell.1 0.9442624 -1.3557627 1.5239438 -0.3786813 -2.0367506324 ## 16cell.2 -1.4033309 0.5669192 -0.5764371 0.2240873 0.2092731123 ## 16cell.3 2.1822899 0.3327657 -3.9188841 -0.2036249 -1.1033810361 ## 16cell.4 1.5970783 -1.1079176 -0.6441109 -2.8524393 0.0004546378 ## 16cell.5 2.7023565 1.1374510 -2.8720566 -1.0064513 1.8063507928 ## PC33 PC34 PC35 PC36 PC37 ## 16cell 1.1394308 0.3840000 -0.30028319 0.5470062 -2.2521121 ## 16cell.1 0.4802093 -1.5461206 0.57785418 0.2136878 -3.1427911 ## 16cell.2 -0.6020883 0.2587835 -1.39670584 1.0217782 -0.9796248 ## 16cell.3 -2.0222558 -1.5459463 0.98029013 1.6982863 -2.3282394 ## 16cell.4 -0.8323239 0.7580553 -0.08445444 -0.3581607 1.2995240 ## 16cell.5 -0.2765822 1.4528263 -0.01488841 -2.0533203 0.9582204 ## PC38 PC39 PC40 PC41 PC42 ## 16cell 1.54130056 -0.5503021 1.8218871 -1.2491319 0.02774323 ## 16cell.1 -0.06859658 1.0455128 3.3915829 0.8911611 1.76258371 ## 16cell.2 -0.93454517 -1.4591025 0.1484064 0.7292182 0.89423648 ## 16cell.3 -0.95838032 0.1684409 0.6182237 0.8339745 -0.21181011 ## 16cell.4 1.57202989 0.8189163 -2.3331272 -0.3108283 -0.31856432 ## 16cell.5 1.45162192 2.1979823 1.0272293 -3.8152357 0.07293698 ## PC43 PC44 PC45 PC46 PC47 PC48 ## 16cell -1.2648452 1.3478074 -1.489203 1.6186833 -0.3300131 0.8603107 ## 16cell.1 1.2310412 -0.3182549 -1.857164 -2.9553566 -2.2298687 0.4699274 ## 16cell.2 0.6198856 1.9024444 0.096746 1.0150184 1.5574517 -0.3872533 ## 16cell.3 -1.1234170 1.0566629 -1.311480 -0.4328987 2.7491211 -0.6665591 ## 16cell.4 0.5818659 -1.2131792 1.086794 0.3857532 2.3153699 1.2776942 ## 16cell.5 -0.8961840 -0.1003433 1.667234 1.5554497 -0.9303923 -0.8338826 ## PC49 PC50 ## 16cell -1.1294170 0.54900311 ## 16cell.1 -0.9080707 -1.77789141 ## 16cell.2 1.4262577 -0.08018494 ## 16cell.3 -0.4120873 2.00067268 ## 16cell.4 -0.9602715 -0.02929732 ## 16cell.5 1.2653639 1.63364381 dim(pca) ## [1] 268 50 # Add PCA data to the deng_SCE object. deng_SCE$PC1 &lt;- pca[, 1] deng_SCE$PC2 &lt;- pca[, 2] # Plot PC biplot with cells colored by cell_type2. # colData(deng_SCE) accesses the cell metadata DataFrame object for deng_SCE. # Look at Figure 1A of the paper as a comparison to your PC biplot. ggplot(as.data.frame(colData(deng_SCE)), aes(x = PC1, y = PC2, color = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;PC1&quot;) + ylab(&quot;PC2&quot;) + ggtitle(&quot;PC biplot&quot;) # PCA is a simple approach and can be good to compare to more complex algorithms # designed to capture differentiation processes. As a simple measure of pseudotime # we can use the coordinates of PC1. # Plot PC1 vs cell_type2. deng_SCE$pseudotime_PC1 &lt;- rank(deng_SCE$PC1) # rank cells by their PC1 score ggplot(as.data.frame(colData(deng_SCE)), aes(x = pseudotime_PC1, y = cell_type2, colour = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;PC1&quot;) + ylab(&quot;Timepoint&quot;) + ggtitle(&quot;Cells ordered by first principal component&quot;) ggsave(paste0(mydir, &quot;/pseudotime_PC1.png&quot;)) ## Saving 7 x 5 in image # Try separating the cell types using other PCs. How does the separation look? 16.3 Diffusion map pseudotime Let us see how a more advance trajectory inference method, diffusion maps and diffusion pseudotime, performs at placing cells along the expected differentiation trajectory. Diffusion maps were introduced by Ronald Coifman and Stephane Lafon, and the underlying idea is to assume that the data are samples from a diffusion process. The method infers the low-dimensional manifold by estimating the eigenvalues and eigenvectors for the diffusion operator related to the data. Angerer et al have applied the diffusion maps concept to the analysis of single-cell RNA-seq data to create an R package called destiny. We will use two forms of pseudotime: the first diffusion component and the diffusion pseudotime. # Prepare a counts matrix with labeled rows and columns. deng &lt;- logcounts(deng_SCE) # access log-transformed counts matrix cellLabels &lt;- deng_SCE$cell_type2 colnames(deng) &lt;- cellLabels # Make a diffusion map. dm &lt;- DiffusionMap(t(deng)) # Optional: Try different sigma values when making diffusion map. # dm &lt;- DiffusionMap(t(deng), sigma = &quot;local&quot;) # use local option to set sigma # sigmas &lt;- find_sigmas(t(deng), verbose = FALSE) # find optimal sigma # dm &lt;- DiffusionMap(t(deng), sigma = optimal_sigma(sigmas)) # Plot diffusion component 1 vs diffusion component 2 (DC1 vs DC2). tmp &lt;- data.frame(DC1 = eigenvectors(dm)[, 1], DC2 = eigenvectors(dm)[, 2], Timepoint = deng_SCE$cell_type2) ggplot(tmp, aes(x = DC1, y = DC2, colour = Timepoint)) + geom_point() + scale_color_tableau() + xlab(&quot;Diffusion component 1&quot;) + ylab(&quot;Diffusion component 2&quot;) + theme_classic() # Try plotting higher diffusion components against one another. # Next, let us use the first diffusion component (DC1) as a measure of pseudotime. # How does the separation by cell stage look? deng_SCE$pseudotime_diffusionmap &lt;- rank(eigenvectors(dm)[,1]) # rank cells by their dpt ggplot(as.data.frame(colData(deng_SCE)), aes(x = pseudotime_diffusionmap, y = cell_type2, colour = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;Diffusion component 1 (DC1)&quot;) + ylab(&quot;Timepoint&quot;) + ggtitle(&quot;Cells ordered by DC1&quot;) ggsave(paste0(mydir, &quot;/pseudotime_DC1.png&quot;)) ## Saving 7 x 5 in image # Plot eigenvalues of diffusion distance matrix. How many diffusion components would you use? # This is analagous to the PC elbow plot (scree plot) that we previously used to assess how # many PCs to use in downstream applications like clustering. plot(eigenvalues(dm), ylim = 0:1, pch = 20, xlab = &#39;Diffusion component (DC)&#39;, ylab = &#39;Eigenvalue&#39;) # What happens if you run the diffusion map on the PCs? Why would one do this? rownames(pca) &lt;- cellLabels dm &lt;- DiffusionMap(pca) # Diffusion pseudotime calculation. # Set index or tip of pseudotime calculation to be a zygotic cell (cell 268). dpt &lt;- DPT(dm, tips = 268) # Plot DC1 vs DC2 and color the cells by their inferred diffusion pseudotime. # We can accesss diffusion pseudotime via dpt$dpt. df &lt;- data.frame(DC1 = eigenvectors(dm)[, 1], DC2 = eigenvectors(dm)[, 2], dptval = dpt$dpt, cell_type2 = deng_SCE$cell_type2) p1 &lt;- ggplot(df) + geom_point(aes(x = DC1, y = DC2, color = dptval)) p2 &lt;- ggplot(df) + geom_point(aes(x = DC1, y = DC2, color = cell_type2)) p &lt;- plot_grid(p1, p2) p save_plot(paste0(mydir, &quot;/dpt_celltype.png&quot;), p, base_height = 5, base_aspect_ratio = 2) # Plot diffusion pseudotime vs timepoint. # Which separates the data better, DC1 or diffusion pseudotime? deng_SCE$pseudotime_dpt &lt;- rank(dpt$dpt) ggplot(as.data.frame(colData(deng_SCE)), aes(x = pseudotime_dpt, y = cell_type2, colour = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;Diffusion map pseudotime (dpt)&quot;) + ylab(&quot;Timepoint&quot;) + ggtitle(&quot;Cells ordered by diffusion map pseudotime&quot;) ggsave(paste0(mydir, &quot;/pseudotime_dpt.png&quot;)) ## Saving 7 x 5 in image # Save current progress. # save(deng_SCE, file = Rda.destiny.path) # To load the data, run the following command. # load(Rda.destiny.path) 16.4 Slingshot map pseudotime Let us see how another advance trajectory inference method, Slingshot, performs at placing cells along the expected differentiation trajectory. library(slingshot) library(Seurat) # Read the Slingshot documentation (?slingshot) and then run Slingshot below. # Given your understanding of the algorithm and the documentation, what is one # major set of parameters we omitted here when running Slingshot? sce &lt;- slingshot(deng_SCE, reducedDim = &#39;PCA&#39;) # no clusters # Plot PC1 vs PC2 colored by Slingshot pseudotime. colors &lt;- rainbow(50, alpha = 1) plot(reducedDims(sce)$PCA, col = colors[cut(sce$slingPseudotime_1,breaks=50)], pch=16, asp = 1) lines(SlingshotDataSet(sce), lwd=2) # Plot Slingshot pseudotime vs cell stage. ggplot(as.data.frame(colData(deng_SCE)), aes(x = sce$slingPseudotime_1, y = cell_type2, colour = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;Slingshot pseudotime&quot;) + ylab(&quot;Timepoint&quot;) + ggtitle(&quot;Cells ordered by Slingshot pseudotime&quot;) # Cluster cells using the Seurat workflow below. gcdata &lt;- CreateSeuratObject(counts = counts(deng_SCE), min.cells = 0, min.genes = 0, project = &quot;slingshot&quot;) gcdata &lt;- NormalizeData(object = gcdata, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) gcdata &lt;- FindVariableGenes(object = gcdata, mean.function = ExpMean, dispersion.function = LogVMR, x.low.cutoff = 0.1, x.high.cutoff = 3, y.cutoff = 0.5) gcdata &lt;- ScaleData(object = gcdata, do.center = T, do.scale = F) gcdata &lt;- RunPCA(object = gcdata, pc.genes = gcdata@var.genes, do.print = TRUE, pcs.print = 1:5, genes.print = 5) gcdata &lt;- FindClusters(object = gcdata, reduction.type = &quot;pca&quot;, dims.use = 1:20, resolution = 0.6, print.output = 0, save.SNN = TRUE) # Add clustering information from Seurat to the deng_SCE object # Then run Slingshot using these cluster assignments. deng_SCE$slingPseudotime_1 &lt;- NULL # remove old slingshot pseudotime data colData(deng_SCE)$Seurat_clusters &lt;- as.character(gcdata@ident) # go from factor to character deng_SCE &lt;- slingshot(deng_SCE, clusterLabels = &#39;Seurat_clusters&#39;, reducedDim = &#39;PCA&#39;) # Plot PC1 vs PC2 colored by Slingshot pseudotime. colors &lt;- rainbow(50, alpha = 1) plot(reducedDims(deng_SCE)$PCA, col = colors[cut(deng_SCE$slingPseudotime_1,breaks=50)], pch=16, asp = 1) lines(SlingshotDataSet(deng_SCE), lwd=2) # Plot Slingshot pseudotime vs cell stage. ggplot(as.data.frame(colData(deng_SCE)), aes(x = slingPseudotime_1, y = cell_type2, colour = cell_type2)) + geom_quasirandom(groupOnX = FALSE) + scale_color_tableau() + theme_classic() + xlab(&quot;Slingshot pseudotime&quot;) + ylab(&quot;Timepoint&quot;) + ggtitle(&quot;Cells ordered by Slingshot pseudotime&quot;) ggsave(paste0(mydir, &quot;/pseudotime_slingshot.png&quot;)) # Save current progress. # save(deng_SCE, file = Rda.slingshot.path) # To load the data, run the following command. # load(Rda.slingshot.path) 16.5 Find temporally expressed genes In this final analysis code chunk, we will identify temporally expressed genes, ie those genes whose expression is changing in a continuous manner over pseudotime. To do this, we will fit a GAM with a LOESS term for pseudotime. Functions for fitting and working with generalized additive models, as described in “Generalized Additive Models” (Hastie and Tibshirani, 1990). Read more about GAMs install.packages(&quot;gam&quot;) library(gam) # Only look at the 1,000 most variable genes when identifying temporally expressesd genes. # Identify the variable genes by ranking all genes by their variance. Y &lt;- log2(counts(deng_SCE) + 1) var1K &lt;- names(sort(apply(Y, 1, var),decreasing = TRUE))[1:1000] Y &lt;- Y[var1K, ] # only counts for variable genes # Fit GAM for each gene using pseudotime as independent variable. t &lt;- deng_SCE$slingPseudotime_1 gam.pval &lt;- apply(Y, 1, function(z){ d &lt;- data.frame(z=z, t=t) tmp &lt;- gam(z ~ lo(t), data=d) p &lt;- summary(tmp)[4][[1]][1,5] p }) # Identify genes with the most significant time-dependent model fit. topgenes &lt;- names(sort(gam.pval, decreasing = FALSE))[1:100] # Prepare and plot a heatmap of the top genes that vary their expression over pseudotime. require(clusterExperiment) heatdata &lt;- as.matrix(gcdata@data[rownames(gcdata@data) %in% topgenes, order(t, na.last = NA)]) heatclus &lt;- gcdata@ident[order(t, na.last = NA)] png(paste0(mydir, &quot;heatmap_time_genes.png&quot;), width=10, height=10, units = &quot;in&quot;, res=200) ce &lt;- ClusterExperiment(heatdata, heatclus, transformation = log1p) clusterExperiment::plotHeatmap(ce, clusterSamplesData = &quot;orderSamplesValue&quot;, visualizeData = &#39;transformed&#39;, cexRow = 1.5, fontsize = 15) dev.off() 16.6 Comparison of the different trajectory inference methods How do the trajectories inferred by PCA, diffusion pseudotime, and slingshot pseudotime compare to one another? install.packages(&quot;corrplot&quot;) library(corrplot) # Prepare data frame with different pseudotime measures. df_pseudotime &lt;- as.data.frame(colData(deng_SCE)[, c(&quot;pseudotime_PC1&quot;, &quot;pseudotime_dpt&quot;, &quot;slingPseudotime_1&quot;)]) colnames(df_pseudotime) &lt;- c(&quot;PC1&quot;, &quot;diffusion&quot;, &quot;slingshot&quot;) # Plot correlation between different pseudotime measures. corrplot.mixed(cor(df_pseudotime, use = &quot;na.or.complete&quot;), order = &quot;hclust&quot;, tl.col = &quot;black&quot;, main = &quot;Correlation matrix for pseudotime results&quot;, mar = c(0, 0, 3.1, 0)) 16.7 Plots of gene expression over time. Visualize how some of the temporally expressed genes change in time. plotExpression(deng_SCE, &quot;Obox5&quot;, x = &quot;PC1&quot;, colour_by = &quot;cell_type2&quot;, show_violin = FALSE, show_smooth = TRUE) plotExpression(deng_SCE, &quot;Obox5&quot;, x = &quot;pseudotime_dpt&quot;, colour_by = &quot;cell_type2&quot;, show_violin = FALSE, show_smooth = TRUE) plotExpression(deng_SCE, &quot;Obox5&quot;, x = &quot;slingPseudotime_1&quot;, colour_by = &quot;cell_type2&quot;, show_violin = FALSE, show_smooth = TRUE) 16.8 Acknowledgements This document builds off chapter 8.4 from the Hemberg lab single cell RNA-seq course, from the Destiny vignette and from the Slingshot vignette. "],
["single-cell-multiomic-technologies.html", "17 Single Cell Multiomic Technologies", " 17 Single Cell Multiomic Technologies "],
["cite-seq-and-scatac-seq.html", "18 CITE-seq and scATAC-seq 18.1 Load settings and packages 18.2 Load in the data 18.3 Setup a Seurat object, and cluster cells based on RNA expression 18.4 Add the protein expression levels to the Seurat object 18.5 Visualize protein levels on RNA clusters 18.6 Identify differentially expressed proteins between clusters 18.7 Cluster directly on protein levels 18.8 Additional exploration: another example of multi-modal analysis 18.9 Acknowledgements", " 18 CITE-seq and scATAC-seq In this lab, we will look at how single cell RNA-seq and single cell protein expression measurement datasets can be jointly analyzed, as part of a CITE-Seq experiment. To learn more about how the antibody barcode matrix is computationally generated from the sequencing data, please visit CITE-seq-Count. To learn more about CITE-Seq and feature barcoding, please visit the CITE-seq site. Note: you can increase the system memory available to Docker by going to Docker -&gt; Preferences -&gt; Advanced and shifting the Memory slider. 18.1 Load settings and packages 18.2 Load in the data This vignette demonstrates new features that allow users to analyze and explore multi-modal data with Seurat. While this represents an initial release, we are excited to release significant new functionality for multi-modal datasets in the future. Here, we analyze a dataset of 8,617 cord blood mononuclear cells (CBMCs), produced with CITE-seq, where we simultaneously measure the single cell transcriptomes alongside the expression of 11 surface proteins, whose levels are quantified with DNA-barcoded antibodies. First, we load in two count matrices : one for the RNA measurements, and one for the antibody-derived tags (ADT). You can download the ADT file here and the RNA file here # Load in the RNA UMI matrix # Note that this dataset also contains ~5% of mouse cells, which we can use # as negative controls for the protein measurements. For this reason, the # gene expression matrix has HUMAN_ or MOUSE_ appended to the beginning of # each gene. cbmc.rna &lt;- read.csv(paste0(mydir, &quot;GSE100866_CBMC_8K_13AB_10X-RNA_umi.csv.gz&quot;), sep = &quot;,&quot;, header = TRUE, row.names = 1) cbmc.rna[20400:20403,1:2] ## CTGTTTACACCGCTAG CTCTACGGTGTGGCTC ## HUMAN_hsa-mir-7515 0 0 ## HUMAN_hsa-mir-8072 0 0 ## MOUSE_0610007N19Rik 14 2 ## MOUSE_0610007P14Rik 2 9 # To make life a bit easier going forward, we&#39;re going to discard all but # the top 100 most highly expressed mouse genes, and remove the &#39;HUMAN_&#39; # from the CITE-seq prefix cbmc.rna.collapsed &lt;- CollapseSpeciesExpressionMatrix(cbmc.rna) rm(cbmc.rna) # free up memory # Load in the ADT UMI matrix cbmc.adt &lt;- read.csv(paste0(mydir, &quot;GSE100866_CBMC_8K_13AB_10X-ADT_umi.csv.gz&quot;), sep = &quot;,&quot;, header = TRUE, row.names = 1) # To avoid any confusion where genes and proteins might have the same name, # we&#39;ll append &#39;CITE_&#39; to each of the ADT rownames. This is not strictly # necessary, but it helps for clarity cbmc.citeseq &lt;- cbmc.adt rownames(cbmc.citeseq) &lt;- paste0(&quot;CITE_&quot;, rownames(cbmc.adt)) # Lastly, we observed poor enrichments for CCR5, CCR7, and CD10 - and # therefore remove them from the matrix. cbmc.citeseq &lt;- cbmc.citeseq[setdiff(rownames(cbmc.citeseq), c(&quot;CITE_CCR5&quot;, &quot;CITE_CCR7&quot;, &quot;CITE_CD10&quot;)), ] # Look at structure of ADT matrix. cbmc.adt[1:10,1:3] ## CTGTTTACACCGCTAG CTCTACGGTGTGGCTC AGCAGCCAGGCTCATT ## CD3 60 52 89 ## CD4 72 49 112 ## CD8 76 59 61 ## CD45RA 575 3943 682 ## CD56 64 68 87 ## CD16 161 107 117 ## CD10 156 95 113 ## CD11c 77 65 65 ## CD14 206 129 169 ## CD19 70 665 79 # What fraction of cells in the ADT and RNA matrix overlap? length(intersect(colnames(cbmc.rna.collapsed), colnames(cbmc.citeseq))) / length(union(colnames(cbmc.rna.collapsed), colnames(cbmc.citeseq))) ## [1] 1 18.3 Setup a Seurat object, and cluster cells based on RNA expression The steps below represent a quick clustering of the PBMCs based on the scRNA-seq data. For more detail on individual steps or more advanced options, see our PBMC clustering guided tutorial here cbmc &lt;- CreateSeuratObject(counts = cbmc.rna.collapsed) # This code sub-samples the data in order to speed up calculations and not use too much memory. # cbmc &lt;- SetAllIdent(cbmc, id = &quot;orig.ident&quot;) # cbmc &lt;- SubsetData(cbmc, max.cells.per.ident = 2000, random.seed = 1) # cbmc.citeseq &lt;- cbmc.citeseq[, cbmc@cell.names] # standard log-normalization cbmc &lt;- NormalizeData(cbmc) # choose ~1k variable genes cbmc &lt;- FindVariableFeatures(cbmc, do.plot = FALSE, y.cutoff = 0.5) # standard scaling cbmc &lt;- ScaleData(cbmc, display.progress = FALSE) # Run PCA, select 13 PCs for tSNE visualization and graph-based clustering cbmc &lt;- RunPCA(cbmc, pcs.print = 0) ## PCElbowPlot(cbmc) # Cluster the cells using the first 13 principal components. cbmc &lt;- FindClusters(cbmc, dims.use = 1:13, print.output = FALSE) cbmc &lt;- RunTSNE(cbmc, dims.use = 1:13) # Find the markers that define each cluster, and use these to annotate the # clusters, we use max.cells.per.ident to speed up the process cbmc.rna.markers &lt;- FindAllMarkers(cbmc, max.cells.per.ident = 100, logfc.threshold = log(2), only.pos = TRUE, min.diff.pct = 0.3, do.print = F) # Examine top marker genes and identify cell types. cbmc.rna.markers %&gt;% group_by(cluster) %&gt;% top_n(5) genes &lt;- c(&quot;CD3D&quot;, &quot;CD4&quot;, &quot;CD8A&quot;, &quot;CD14&quot;, &quot;MS4A1&quot;, &quot;KLRB1&quot;, &quot;CD34&quot;) FeaturePlot(cbmc, genes, cols.use = c(&quot;lightgrey&quot;, &quot;blue&quot;)) # Which cluster consists of mouse cells? cbmc.rna.markers %&gt;% filter(cluster == 3) current.cluster.ids &lt;- 0:15 # Note, for simplicity we are merging two CD14+ Mono clusters (that differ # in the expression of HLA-DR genes), and two NK clusters (that differ in # cell cycle stage) new.cluster.ids &lt;- c(&quot;CD4 T&quot;, &quot;CD14+ Mono&quot;, &quot;CD14+ Mono&quot;, &quot;NK&quot;, &quot;Mouse&quot;, &quot;B&quot;, &quot;CD8 T&quot;, &quot;CD16+ Mono&quot;, &quot;Unknown&quot;, &quot;CD34+&quot;, &quot;Mk&quot;, &quot;Eryth&quot;, &quot;DC&quot;, &quot;Mouse&quot;, &quot;pDC&quot;, &quot;NK&quot;) cbmc@ident &lt;- plyr::mapvalues(x = cbmc@ident, from = current.cluster.ids, to = new.cluster.ids) TSNEPlot(cbmc, do.label = TRUE, pt.size = 0.5) # Save current progress. # save(cbmc, cbmc.rna.markers, file = Rda.RNA.path) # To load the data, run the following command. # load(Rda.RNA.path) 18.4 Add the protein expression levels to the Seurat object Seurat v2.1 allows you to store information from multiple assays in the same object, as long as the data is multi-modal (collected on the same set of cells). You can use the SetAssayData and GetAssayData accessor functions to add and fetch data from additional assays. # We will define a CITE assay, and store raw data for it. Note that it&#39;s # convenient, but not required, to use the same name as the rowname prefix # we defined earlier. # If you are interested in how these data are internally stored, you can # check out the @assay slot, and the assay class, which is defined in # multimodal.R Note that RNA data is still stored in its normal slots, but # can also be accessed using GetAssayData and SetAssayData, using the &#39;RNA&#39; # assay cbmc &lt;- SetAssayData(cbmc, assay.type = &quot;CITE&quot;, slot = &quot;raw.data&quot;, new.data = cbmc.citeseq) GetAssayData(cbmc, assay.type = &quot;CITE&quot;, slot = &quot;raw.data&quot;)[1:3,1:3] cbmc@assay$CITE@raw.data[1:3,1:3] # Now we can repeat the preprocessing (normalization and scaling) steps that # we typically run with RNA, but modifying the &#39;assay.type&#39; argument. For # CITE-seq data, we do not recommend typical LogNormalization. Instead, we # use a centered log-ratio (CLR) normalization, computed independently for # each gene. This is a slightly improved procedure from the original # publication, and we will release more advanced versions of CITE-seq # normalizations soon. cbmc &lt;- NormalizeData(cbmc, assay.type = &quot;CITE&quot;, normalization.method = &quot;genesCLR&quot;) GetAssayData(cbmc, assay.type = &quot;CITE&quot;, slot = &quot;data&quot;)[1:3,1:3] cbmc &lt;- ScaleData(cbmc, assay.type = &quot;CITE&quot;, display.progress = FALSE) cbmc@assay$CITE@scale.data[1:3,1:3] 18.5 Visualize protein levels on RNA clusters You can use the names of any ADT markers, (i.e. “CITE_CD4”), in FetchData, FeaturePlot, RidgePlot, GenePlot, DoHeatmap, or any other visualization features # In this plot, protein (ADT) levels are on top, and RNA levels are on bottom FeaturePlot(cbmc, features.plot = c(&quot;CITE_CD3&quot;, &quot;CITE_CD11c&quot;, &quot;CITE_CD8&quot;, &quot;CITE_CD16&quot;, &quot;CD3E&quot;, &quot;ITGAX&quot;, &quot;CD8A&quot;, &quot;FCGR3A&quot;), min.cutoff = &quot;q05&quot;, max.cutoff = &quot;q95&quot;, nCol = 4, cols.use = c(&quot;lightgrey&quot;, &quot;blue&quot;), pt.size = 0.5) # How do the gene and protein expression levels compare to one another? # Compare gene and protein expression levels for the other 6 antibodies. FeaturePlot(cbmc, features.plot = c(&quot;CITE_CD4&quot;, &quot;CITE_CD45RA&quot;, &quot;CITE_CD56&quot;, &quot;CITE_CD14&quot;, &quot;CITE_CD19&quot;, &quot;CITE_CD34&quot;, &quot;CD4&quot;, &quot;PTPRC&quot;, &quot;NCAM1&quot;, &quot;CD14&quot;, &quot;CD19&quot;, &quot;CD34&quot;), min.cutoff = &quot;q05&quot;, max.cutoff = &quot;q95&quot;, nCol = 6, cols.use = c(&quot;lightgrey&quot;, &quot;blue&quot;), pt.size = 0.5) # Ridge plots are another useful visualization. RidgePlot(cbmc, features.plot = c(&quot;CITE_CD3&quot;, &quot;CITE_CD11c&quot;, &quot;CITE_CD8&quot;, &quot;CITE_CD16&quot;), nCol = 2) par(mfrow = c(1, 2)) # Draw ADT scatter plots (like biaxial plots for FACS). Note that you can # even &#39;gate&#39; cells if desired by setting do.identify = TRUE or # interact with cells by setting do.hover = TRUE GenePlot(cbmc, gene1 = &quot;CITE_CD19&quot;, gene2 = &quot;CITE_CD3&quot;, cex = 0.5) # view relationship between protein and RNA GenePlot(cbmc, gene1 = &quot;CITE_CD3&quot;, gene2 = &quot;CD3E&quot;, cex.use = 0.5) # Let&#39;s plot CD4 vs CD8 levels in T cells tcells &lt;- SubsetData(cbmc, ident.use = c(&quot;CD4 T&quot;, &quot;CD8 T&quot;)) par(mfrow = c(1, 2)) GenePlot(tcells, gene1 = &quot;CITE_CD4&quot;, gene2 = &quot;CITE_CD8&quot;, cex = 0.5) # Let&#39;s look at the raw (non-normalized) ADT counts. You can see the values # are quite high, particularly in comparison to RNA values. This is due to # the significantl higher protein copy number in cells, which significantly # reduces &#39;drop-out&#39; in ADT data GenePlot(tcells, gene1 = &quot;CITE_CD4&quot;, gene2 = &quot;CITE_CD8&quot;, use.raw = TRUE, cex = 0.5) # If you look a bit more closely, you&#39;ll see that our CD8 T cell cluster is # enriched for CD8 T cells, but still contains many CD4+ CD8- T cells. This # is because Naive CD4 and CD8 T cells are quite similar transcriptomically, # and the RNA dropout levels for CD4 and CD8 are quite high. This # demonstrates the challenge of defining subtle immune cell differences from # scRNA-seq data alone. # What fraction of T cells are double negative in gene expression? (CD4- and CD8-) # You can use an interactive plot to gate on the cells (do.identify = T) or use # Boolean conditions on CD4 and CD8A expression to find double negative cells. # cells &lt;- GenePlot(tcells, gene1 = &quot;CD4&quot;, gene2 = &quot;CD8A&quot;, cex = 0.5, do.identify = T) # length(cells) / length(tcells@cell.names) length(which(tcells@data[&quot;CD4&quot;, ] == 0 &amp; tcells@data[&quot;CD8A&quot;, ] == 0)) # What fraction of T cells are double negative in protein expression? (CD4- and CD8-) # cells &lt;- GenePlot(tcells, gene1 = &quot;CITE_CD4&quot;, gene2 = &quot;CITE_CD8&quot;, cex = 0.5, do.identify = T) # length(cells) / length(tcells@cell.names) length(which(tcells@assay$CITE@data[&quot;CITE_CD4&quot;, ] &lt; 1 &amp; tcells@assay$CITE@data[&quot;CITE_CD8&quot;, ] &lt; 1)) 18.6 Identify differentially expressed proteins between clusters mono.markers &lt;- FindMarkers(cbmc, &quot;CD14+ Mono&quot;, &quot;CD16+ Mono&quot;, assay.type = &quot;CITE&quot;, logfc.threshold = log(1.5)) head(mono.markers) # Plot the expression of the monocyte markers you identified. FeaturePlot(cbmc, features.plot = c(&quot;CITE_CD14&quot;, &quot;CITE_CD16&quot;), min.cutoff = &quot;q05&quot;, max.cutoff = &quot;q95&quot;, nCol = 4, cols.use = c(&quot;lightgrey&quot;, &quot;blue&quot;), pt.size = 0.5) # Note that we observe CD14 protein expression only on CD4+ T cells, as has # been previously observed in the literature tcell.markers &lt;- FindMarkers(cbmc, ident.1 = &quot;CD4 T&quot;, ident.2 = &quot;CD8 T&quot;, assay.type = &quot;CITE&quot;, logfc.threshold = log(1.5)) head(tcell.markers) # Downsample the clusters to a maximum of 300 cells each (makes the heatmap # easier to see for small clusters) cbmc.small &lt;- SubsetData(cbmc, max.cells.per.ident = 300) # Find protein markers for all clusters, and draw a heatmap adt.markers &lt;- FindAllMarkers(cbmc.small, assay.type = &quot;CITE&quot;, only.pos = TRUE, print.bar = F) DoHeatmap(cbmc.small, genes.use = unique(adt.markers$gene), assay.type = &quot;CITE&quot;, slim.col.label = TRUE, remove.key = TRUE, group.label.rot = TRUE) # You can see that our unknown cells co-express both myeloid and lymphoid # markers (true at the RNA level as well). They are likely cell clumps # (multiplets) that should be discarded. We&#39;ll remove the mouse cells now as # well cbmc &lt;- SubsetData(cbmc, ident.remove = c(&quot;Unknown&quot;, &quot;Mouse&quot;)) 18.7 Cluster directly on protein levels You can also run dimensional reduction and graph-based clustering directly on CITE-seq data # We will store the results in a new object, cbmc_cite. cbmc_cite &lt;- RunPCA(cbmc, pc.genes = rownames(cbmc.citeseq), assay.type = &quot;CITE&quot;, pcs.print = 0) PCAPlot(cbmc_cite, pt.size = 0.5) # Since we only have 10 markers, instead of doing PCA, we&#39;ll just use a # standard euclidean distance matrix here. Also, this provides a good # opportunity to demonstrate how to do visualization and clustering using a # custom distance matrix in Seurat. adt.data &lt;- GetAssayData(cbmc_cite, assay.type = &quot;CITE&quot;, slot = &quot;data&quot;) adt.dist &lt;- as.matrix(dist(t(adt.data))) # Why do we not use PCA to do dimensionality reduction here? # Is Euclidean distance a good distance metric in this case? PCElbowPlot(cbmc_cite) # Before we recluster the data on ADT levels, we&#39;ll stash the RNA cluster # IDs for later cbmc_cite &lt;- StashIdent(cbmc_cite, &quot;rnaClusterID&quot;) # Now, we rerun tSNE using our distance matrix defined only on ADT (protein) # levels. cbmc_cite &lt;- RunTSNE(cbmc_cite, distance.matrix = adt.dist) # We can also rerun clustering using the same distance matrix. We&#39;ll start # with a very coarse clustering (resolution=0.2) cbmc_cite &lt;- FindClusters(cbmc_cite, distance.matrix = adt.dist, print.output = FALSE, resolution = 0.2) # We can compare the RNA and protein clustering, and use this to annotate # the protein clustering (we could also of course use FindMarkers) clustering.table &lt;- table(cbmc_cite@ident, cbmc_cite@meta.data$rnaClusterID) current.cluster.ids &lt;- 0:10 # Note, for simplicity we are merging two CD14+ Mono clusters (that differ # in the expression of HLA-DR genes), and two NK clusters (that differ in # cell cycle stage) new.cluster.ids &lt;- c(&quot;CD4 T&quot;, &quot;CD14+ Mono&quot;, &quot;NK&quot;, &quot;B&quot;, &quot;CD8 T&quot;, &quot;CD34+&quot;, &quot;Unknown1&quot;, &quot;CD16+ Mono&quot;, &quot;Unknown2&quot;, &quot;pDC&quot;, &quot;Unknown3&quot;) cbmc_cite@ident &lt;- plyr::mapvalues(x = cbmc_cite@ident, from = current.cluster.ids, to = new.cluster.ids) tsne_rnaClusters &lt;- TSNEPlot(cbmc_cite, do.return = TRUE, group.by = &quot;rnaClusterID&quot;, pt.size = 0.5, do.label = T) tsne_rnaClusters &lt;- tsne_rnaClusters + ggtitle(&quot;Clustering based on scRNA-seq&quot;) + theme(plot.title = element_text(hjust = 0.5)) tsne_adtClusters &lt;- TSNEPlot(cbmc_cite, do.return = TRUE, pt.size = 0.5, do.label = T) tsne_adtClusters &lt;- tsne_adtClusters + ggtitle(&quot;Clustering based on ADT signal&quot;) + theme(plot.title = element_text(hjust = 0.5)) # Note: for this comparison, both the RNA and protein clustering are # visualized on a tSNE generated using the ADT distance matrix. plot_grid(tsne_rnaClusters, tsne_adtClusters, ncol = 2) # What differences if any do you see between the clustering based on scRNA-seq # and the clustering based on ADT signal? # How could we combine these datasets in a joint, integrative analysis? # Save current progress. # save(cbmc_cite, file = Rda.protein.path) # To load the data, run the following command. # load(Rda.protein.path) The ADT-based clustering yields similar results, but with a few differences Clustering is improved for CD4/CD8 T cell populations, based on the robust ADT data for CD4, CD8, CD14, and CD45RA However, some clusters for which the ADT data does not contain good distinguishing protein markers (i.e. Mk/Ery/DC) lose separation Notably, our unknown populations again correspond to rare populations that co-express markers for different lineages Unknown 1 (Myeloid/CD4), (Myeloid/CD8), and 3 (B/CD4) likely correspond to additional doublets, whose signal was too subtle to cluster separately in scRNA-seq You can verify this using FindMarkers at the RNA level, as well 18.8 Additional exploration: another example of multi-modal analysis For another nice example of multi-modal analysis, please explore this single cell ATAC-Seq vignette 18.9 Acknowledgements This document is largely a tutorial from Seurat website, with some small modifications. The official vignette is available at CITE-Seq Seurat. "],
["single-cell-resources.html", "19 Single Cell Resources 19.1 Comprehensive list of single-cell resources 19.2 Computational packages for single-cell analysis 19.3 eLife Commentary on the Human Cell Atlas 19.4 Online courses", " 19 Single Cell Resources 19.1 Comprehensive list of single-cell resources https://github.com/seandavi/awesome-single-cell 19.2 Computational packages for single-cell analysis http://bioconductor.org/packages/devel/workflows/html/simpleSingleCell.html https://satijalab.org/seurat/ https://scanpy.readthedocs.io/ 19.3 eLife Commentary on the Human Cell Atlas link - Nature Commentary on the Human Cell Atlas - https://www.nature.com/news/the-human-cell-atlas-from-vision-to-reality-1.22854 19.4 Online courses https://hemberg-lab.github.io/scRNA.seq.course/ https://github.com/SingleCellTranscriptomics https://r4ds.had.co.nz/ "],
["references.html", "References", " References "]
]
